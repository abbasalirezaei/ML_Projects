{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3949e7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16512 entries, 2072 to 2575\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           16512 non-null  float64\n",
      " 1   latitude            16512 non-null  float64\n",
      " 2   housing_median_age  16512 non-null  float64\n",
      " 3   total_rooms         16512 non-null  float64\n",
      " 4   total_bedrooms      16336 non-null  float64\n",
      " 5   population          16512 non-null  float64\n",
      " 6   households          16512 non-null  float64\n",
      " 7   median_income       16512 non-null  float64\n",
      " 8   median_house_value  16512 non-null  float64\n",
      " 9   ocean_proximity     16512 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom sklearn.model_selection import train_test_split\\nfrom pandas.plotting import scatter_matrix\\nfrom sklearn.impute import SimpleImputer\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.preprocessing import OneHotEncoder\\n\\n%load_ext nb_black\\n# =====================\\nhousing = pd.read_csv(r\\\"housing.csv\\\")\\n\\n# housing.head(20)\\n# housing.tail()\\n# housing[1:5]\\n# housing.shape\\n# housing.info()\\n# housing.columns\\n# housing['ocean_proximity'].unique()\\n# housing[\\\"ocean_proximity\\\"].value_counts()\\n# housing[housing[\\\"ocean_proximity\\\"] == \\\"ISLAND\\\"]\\n# housing[[\\\"population\\\", \\\"median_income\\\"]][housing[\\\"ocean_proximity\\\"] == \\\"ISLAND\\\"]\\n# housing.describe()\\n# housing.hist(bins=50, figsize=(20, 15))\\n# plt.show()\\n# ===================\\n\\ntrain_set, test_set = train_test_split(housing, test_size=0.2, random_state=2)\\ntrain_set.shape\\n\\ntest_set.shape\\ntrain_set.info()\\n# housing.info()\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom sklearn.model_selection import train_test_split\\nfrom pandas.plotting import scatter_matrix\\nfrom sklearn.impute import SimpleImputer\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.preprocessing import OneHotEncoder\\n\\n%load_ext nb_black\\n# =====================\\nhousing = pd.read_csv(r\\\"housing.csv\\\")\\n\\n# housing.head(20)\\n# housing.tail()\\n# housing[1:5]\\n# housing.shape\\n# housing.info()\\n# housing.columns\\n# housing['ocean_proximity'].unique()\\n# housing[\\\"ocean_proximity\\\"].value_counts()\\n# housing[housing[\\\"ocean_proximity\\\"] == \\\"ISLAND\\\"]\\n# housing[[\\\"population\\\", \\\"median_income\\\"]][housing[\\\"ocean_proximity\\\"] == \\\"ISLAND\\\"]\\n# housing.describe()\\n# housing.hist(bins=50, figsize=(20, 15))\\n# plt.show()\\n# ===================\\n\\ntrain_set, test_set = train_test_split(housing, test_size=0.2, random_state=2)\\ntrain_set.shape\\n\\ntest_set.shape\\ntrain_set.info()\\n# housing.info()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%load_ext nb_black\n",
    "# =====================\n",
    "housing = pd.read_csv(r\"housing.csv\")\n",
    "\n",
    "# housing.head(20)\n",
    "# housing.tail()\n",
    "# housing[1:5]\n",
    "# housing.shape\n",
    "# housing.info()\n",
    "# housing.columns\n",
    "# housing['ocean_proximity'].unique()\n",
    "# housing[\"ocean_proximity\"].value_counts()\n",
    "# housing[housing[\"ocean_proximity\"] == \"ISLAND\"]\n",
    "# housing[[\"population\", \"median_income\"]][housing[\"ocean_proximity\"] == \"ISLAND\"]\n",
    "# housing.describe()\n",
    "# housing.hist(bins=50, figsize=(20, 15))\n",
    "# plt.show()\n",
    "# ===================\n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=2)\n",
    "train_set.shape\n",
    "\n",
    "test_set.shape\n",
    "train_set.info()\n",
    "# housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e4a5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "median_house_value    1.000000\n",
       "median_income         0.689659\n",
       "total_rooms           0.133218\n",
       "housing_median_age    0.108626\n",
       "households            0.063245\n",
       "total_bedrooms        0.047478\n",
       "population           -0.027441\n",
       "longitude            -0.046754\n",
       "latitude             -0.143970\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# becuse we have lable and we wanna predet the label sooo we have supervised algoritm\\n# and becouse of we donot want classification so we have regresion\\ntrain_set.tail()\\ndata = train_set.copy()\\n# we have the map of california\\n# each point in the plot bellow is a row of the our table\\n# alpha --> \\u0686\\u06af\\u0627\\u0644\\u06cc \\u0645\\u0646\\u0627\\u0637\\u0642 \\u0631\\u0648 \\u0628\\u0647 \\u0645\\u0627 \\u0645\\u06cc\\u062f\\u0647\\n# data.plot(kind=\\\"scatter\\\", x=\\\"longitude\\\", y=\\\"latitude\\\", figsize=(10, 7), alpha=0.2)\\n# ===============================\\n# s for \\u0634\\u0639\\u0627\\u0639 \\u0647\\u0631 \\u062f\\u0627\\u06cc\\u0631\\u0647 \\u062f\\u0631\\n# data.plot(kind=\\\"scatter\\\", x=\\\"longitude\\\", y=\\\"latitude\\\",\\n#           s=data['population']/30,label='population'\\n#           ,figsize=(10, 7), alpha=0.2)\\n# ============================\\n# \\u0645\\u0627 \\u0645\\u06cc\\u0627\\u0646\\u06af\\u06cc\\u0646 \\u0642\\u06cc\\u0645\\u062a \\u062e\\u0627\\u0646\\u0647 \\u062f\\u0631 \\u0647\\u0631\\u0645\\u0646\\u0637\\u0642\\u0647 \\u06a9\\u0647 \\u0648\\u06cc\\u0698\\u06af\\u06cc \\u0627\\u0635\\u0644\\u06cc \\u0645\\u0627 \\u0647\\u0633\\u062a \\u0648 \\u0647\\u062f\\u0641 \\u0645\\u0627 \\u067e\\u06cc\\u0634 \\u0628\\u06cc\\u06cc\\u0646 \\u06cc\\n# \\u0627\\u0648\\u0646 \\u0647\\u0633\\u062a \\u0631\\u0648 \\u0647\\u0645 \\u0648\\u0627\\u0631\\u062f \\u0628\\u0627\\u0632\\u06cc \\u0645\\u06cc \\u06a9\\u0646\\u06cc\\u0645\\n#\\n# data.plot(\\n#     kind=\\\"scatter\\\",\\n#     x=\\\"longitude\\\",\\n#     y=\\\"latitude\\\",\\n#     s=data[\\\"population\\\"] / 30,\\n#     label=\\\"population\\\",\\n#     c=\\\"median_house_value\\\",\\n#     cmap=plt.get_cmap(\\\"jet\\\"),\\n#     figsize=(10, 7),\\n#     alpha=0.2,\\n# )\\n\\n\\n# ================\\n# \\u067e\\u06cc\\u062f\\u0627 \\u06a9\\u0631\\u062f\\u0646 \\u0648\\u0627\\u0628\\u0633\\u062a\\u06af\\u06cc \\u0647\\u0627\\n# \\u0627\\u0632 \\u0647\\u0645\\u0647 \\u0645\\u0647\\u0645 \\u062a\\u0631 \\u067e\\u06cc\\u062f\\u0627 \\u06a9\\u0631\\u062f\\u0646 \\u0648\\u0627\\u0628\\u0633\\u062a\\u06af\\u06cc \\u0633\\u062a\\u0648\\u0646 \\u0647\\u0627\\u06cc  \\u062f\\u06cc\\u06af\\u0631 \\u0628\\u0627 \\u0633\\u062a\\u0648\\u0646 \\u0647\\u062f\\u0641 \\u0627\\u0633...\\n\\n\\n# =============\\n# standard correlation coeficient \\n# \\u0645\\u0642\\u062f\\u0627\\u0631\\u0634 \\u0627\\u0632 -\\u06f1 \\u062a\\u0627 \\u06f1 \\u0647\\u0633\\u062a ... \\u06a9\\u0647 \\u062f\\u0631\\u062c\\u0647 \\u0648\\u0627\\u0628\\u0633\\u062a\\u06af\\u06cc \\u0631\\u0648 \\u0645\\u06cc\\u06af\\u0647 \\u0647\\u0631 \\u0686\\u06cc \\u0628\\u0647  \\u06f1 \\u0646\\u0632\\u062f\\u06cc\\u06a9 \\u062a\\u0631 \\u0628\\u0634\\u0647 \\u0648\\u0627\\u0628\\u0633\\u062a\\u06af\\u06cc\\n# \\u0645\\u062b\\u0628\\u062a \\u062f\\u0627\\u0631\\u0647 ...\\n# \\u0648 \\u0647\\u0631\\u0686\\u06cc \\u0628\\u0647 -\\u06f1 \\u0646\\u0632\\u062f\\u06cc\\u06af \\u0628\\u0634\\u06af\\u06cc \\u0648\\u0627\\u0628\\u0633\\u062a\\u06af\\u06cc \\u0632\\u06cc\\u0627\\u062f\\u06cc \\u062f\\u0627\\u0631\\u0647 \\u0627\\u0645\\u0627 \\u0648\\u0627\\u0628\\u0633\\u062a\\u06af\\u06cc \\u0645\\u0646\\u0641\\u06cc \\n# \\u0636\\u0631\\u06cc\\u0628 \\u0627\\u0633\\u062a\\u0627\\u0646\\u062f\\u0627\\u0631\\u062f \\u0648\\u0627\\u0628\\u0633\\u062a\\u06af\\u06cc\\n# \\u0645\\u0634\\u06a9\\u0644\\u0634 \\u0627\\u06cc\\u0646\\u0647 \\u0641\\u0642\\u0637 \\u0648\\u0627\\u0628\\u0633\\u062a\\u06af\\u06cc \\u0647\\u0627\\u06cc \\u062e\\u0637\\u06cc \\u0631\\u0648 \\u0628\\u0647 \\u0645\\u0627 \\u0645\\u06cc\\u062f\\u0647\\n\\n# find relation of each posssible tuple\\ncorr_matrix = data.corr()\\n# print(corr_matrix)\\ncorr_matrix\\n\\n# becuse of we wanna relation of each row with median_house_value\\n\\n# corr_matrix[\\\"median_house_value\\\"]\\n\\ncorr_matrix[\\\"median_house_value\\\"].sort_values(ascending=False)\";\n",
       "                var nbb_formatted_code = \"# becuse we have lable and we wanna predet the label sooo we have supervised algoritm\\n# and becouse of we donot want classification so we have regresion\\ntrain_set.tail()\\ndata = train_set.copy()\\n# we have the map of california\\n# each point in the plot bellow is a row of the our table\\n# alpha --> \\u0686\\u06af\\u0627\\u0644\\u06cc \\u0645\\u0646\\u0627\\u0637\\u0642 \\u0631\\u0648 \\u0628\\u0647 \\u0645\\u0627 \\u0645\\u06cc\\u062f\\u0647\\n# data.plot(kind=\\\"scatter\\\", x=\\\"longitude\\\", y=\\\"latitude\\\", figsize=(10, 7), alpha=0.2)\\n# ===============================\\n# s for \\u0634\\u0639\\u0627\\u0639 \\u0647\\u0631 \\u062f\\u0627\\u06cc\\u0631\\u0647 \\u062f\\u0631\\n# data.plot(kind=\\\"scatter\\\", x=\\\"longitude\\\", y=\\\"latitude\\\",\\n#           s=data['population']/30,label='population'\\n#           ,figsize=(10, 7), alpha=0.2)\\n# ============================\\n# \\u0645\\u0627 \\u0645\\u06cc\\u0627\\u0646\\u06af\\u06cc\\u0646 \\u0642\\u06cc\\u0645\\u062a \\u062e\\u0627\\u0646\\u0647 \\u062f\\u0631 \\u0647\\u0631\\u0645\\u0646\\u0637\\u0642\\u0647 \\u06a9\\u0647 \\u0648\\u06cc\\u0698\\u06af\\u06cc \\u0627\\u0635\\u0644\\u06cc \\u0645\\u0627 \\u0647\\u0633\\u062a \\u0648 \\u0647\\u062f\\u0641 \\u0645\\u0627 \\u067e\\u06cc\\u0634 \\u0628\\u06cc\\u06cc\\u0646 \\u06cc\\n# \\u0627\\u0648\\u0646 \\u0647\\u0633\\u062a \\u0631\\u0648 \\u0647\\u0645 \\u0648\\u0627\\u0631\\u062f \\u0628\\u0627\\u0632\\u06cc \\u0645\\u06cc \\u06a9\\u0646\\u06cc\\u0645\\n#\\n# data.plot(\\n#     kind=\\\"scatter\\\",\\n#     x=\\\"longitude\\\",\\n#     y=\\\"latitude\\\",\\n#     s=data[\\\"population\\\"] / 30,\\n#     label=\\\"population\\\",\\n#     c=\\\"median_house_value\\\",\\n#     cmap=plt.get_cmap(\\\"jet\\\"),\\n#     figsize=(10, 7),\\n#     alpha=0.2,\\n# )\\n\\n\\n# ================\\n# \\u067e\\u06cc\\u062f\\u0627 \\u06a9\\u0631\\u062f\\u0646 \\u0648\\u0627\\u0628\\u0633\\u062a\\u06af\\u06cc \\u0647\\u0627\\n# \\u0627\\u0632 \\u0647\\u0645\\u0647 \\u0645\\u0647\\u0645 \\u062a\\u0631 \\u067e\\u06cc\\u062f\\u0627 \\u06a9\\u0631\\u062f\\u0646 \\u0648\\u0627\\u0628\\u0633\\u062a\\u06af\\u06cc \\u0633\\u062a\\u0648\\u0646 \\u0647\\u0627\\u06cc  \\u062f\\u06cc\\u06af\\u0631 \\u0628\\u0627 \\u0633\\u062a\\u0648\\u0646 \\u0647\\u062f\\u0641 \\u0627\\u0633...\\n\\n\\n# =============\\n# standard correlation coeficient\\n# \\u0645\\u0642\\u062f\\u0627\\u0631\\u0634 \\u0627\\u0632 -\\u06f1 \\u062a\\u0627 \\u06f1 \\u0647\\u0633\\u062a ... \\u06a9\\u0647 \\u062f\\u0631\\u062c\\u0647 \\u0648\\u0627\\u0628\\u0633\\u062a\\u06af\\u06cc \\u0631\\u0648 \\u0645\\u06cc\\u06af\\u0647 \\u0647\\u0631 \\u0686\\u06cc \\u0628\\u0647  \\u06f1 \\u0646\\u0632\\u062f\\u06cc\\u06a9 \\u062a\\u0631 \\u0628\\u0634\\u0647 \\u0648\\u0627\\u0628\\u0633\\u062a\\u06af\\u06cc\\n# \\u0645\\u062b\\u0628\\u062a \\u062f\\u0627\\u0631\\u0647 ...\\n# \\u0648 \\u0647\\u0631\\u0686\\u06cc \\u0628\\u0647 -\\u06f1 \\u0646\\u0632\\u062f\\u06cc\\u06af \\u0628\\u0634\\u06af\\u06cc \\u0648\\u0627\\u0628\\u0633\\u062a\\u06af\\u06cc \\u0632\\u06cc\\u0627\\u062f\\u06cc \\u062f\\u0627\\u0631\\u0647 \\u0627\\u0645\\u0627 \\u0648\\u0627\\u0628\\u0633\\u062a\\u06af\\u06cc \\u0645\\u0646\\u0641\\u06cc\\n# \\u0636\\u0631\\u06cc\\u0628 \\u0627\\u0633\\u062a\\u0627\\u0646\\u062f\\u0627\\u0631\\u062f \\u0648\\u0627\\u0628\\u0633\\u062a\\u06af\\u06cc\\n# \\u0645\\u0634\\u06a9\\u0644\\u0634 \\u0627\\u06cc\\u0646\\u0647 \\u0641\\u0642\\u0637 \\u0648\\u0627\\u0628\\u0633\\u062a\\u06af\\u06cc \\u0647\\u0627\\u06cc \\u062e\\u0637\\u06cc \\u0631\\u0648 \\u0628\\u0647 \\u0645\\u0627 \\u0645\\u06cc\\u062f\\u0647\\n\\n# find relation of each posssible tuple\\ncorr_matrix = data.corr()\\n# print(corr_matrix)\\ncorr_matrix\\n\\n# becuse of we wanna relation of each row with median_house_value\\n\\n# corr_matrix[\\\"median_house_value\\\"]\\n\\ncorr_matrix[\\\"median_house_value\\\"].sort_values(ascending=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# becuse we have lable and we wanna predet the label sooo we have supervised algoritm\n",
    "# and becouse of we donot want classification so we have regresion\n",
    "train_set.tail()\n",
    "data = train_set.copy()\n",
    "# we have the map of california\n",
    "# each point in the plot bellow is a row of the our table\n",
    "# alpha --> چگالی مناطق رو به ما میده\n",
    "# data.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", figsize=(10, 7), alpha=0.2)\n",
    "# ===============================\n",
    "# s for شعاع هر دایره در\n",
    "# data.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\",\n",
    "#           s=data['population']/30,label='population'\n",
    "#           ,figsize=(10, 7), alpha=0.2)\n",
    "# ============================\n",
    "# ما میانگین قیمت خانه در هرمنطقه که ویژگی اصلی ما هست و هدف ما پیش بیین ی\n",
    "# اون هست رو هم وارد بازی می کنیم\n",
    "#\n",
    "# data.plot(\n",
    "#     kind=\"scatter\",\n",
    "#     x=\"longitude\",\n",
    "#     y=\"latitude\",\n",
    "#     s=data[\"population\"] / 30,\n",
    "#     label=\"population\",\n",
    "#     c=\"median_house_value\",\n",
    "#     cmap=plt.get_cmap(\"jet\"),\n",
    "#     figsize=(10, 7),\n",
    "#     alpha=0.2,\n",
    "# )\n",
    "\n",
    "\n",
    "# ================\n",
    "# پیدا کردن وابستگی ها\n",
    "# از همه مهم تر پیدا کردن وابستگی ستون های  دیگر با ستون هدف اس...\n",
    "\n",
    "\n",
    "# =============\n",
    "# standard correlation coeficient \n",
    "# مقدارش از -۱ تا ۱ هست ... که درجه وابستگی رو میگه هر چی به  ۱ نزدیک تر بشه وابستگی\n",
    "# مثبت داره ...\n",
    "# و هرچی به -۱ نزدیگ بشگی وابستگی زیادی داره اما وابستگی منفی \n",
    "# ضریب استاندارد وابستگی\n",
    "# مشکلش اینه فقط وابستگی های خطی رو به ما میده\n",
    "\n",
    "# find relation of each posssible tuple\n",
    "corr_matrix = data.corr()\n",
    "# print(corr_matrix)\n",
    "corr_matrix\n",
    "\n",
    "# becuse of we wanna relation of each row with median_house_value\n",
    "\n",
    "# corr_matrix[\"median_house_value\"]\n",
    "\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "319e5b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"features = [\\\"median_house_value\\\", \\\"median_income\\\", \\\"total_rooms\\\", \\\"housing_median_age\\\"]\\n# scatter_matrix(data[features], figsize=(15, 10))\\n# plt.show()\";\n",
       "                var nbb_formatted_code = \"features = [\\\"median_house_value\\\", \\\"median_income\\\", \\\"total_rooms\\\", \\\"housing_median_age\\\"]\\n# scatter_matrix(data[features], figsize=(15, 10))\\n# plt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = [\"median_house_value\", \"median_income\", \"total_rooms\", \"housing_median_age\"]\n",
    "# scatter_matrix(data[features], figsize=(15, 10))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10829b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "066f82da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>-119.84</td>\n",
       "      <td>36.77</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>1.4817</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10600</th>\n",
       "      <td>-117.80</td>\n",
       "      <td>33.68</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2032.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>6.9133</td>\n",
       "      <td>274100.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>-120.19</td>\n",
       "      <td>36.60</td>\n",
       "      <td>25.0</td>\n",
       "      <td>875.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>931.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>1.5536</td>\n",
       "      <td>58300.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>-118.32</td>\n",
       "      <td>34.10</td>\n",
       "      <td>31.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.5284</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16541</th>\n",
       "      <td>-121.23</td>\n",
       "      <td>37.79</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>4.0815</td>\n",
       "      <td>117900.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "2072     -119.84     36.77                 6.0       1853.0           473.0   \n",
       "10600    -117.80     33.68                 8.0       2032.0           349.0   \n",
       "2494     -120.19     36.60                25.0        875.0           214.0   \n",
       "4284     -118.32     34.10                31.0        622.0           229.0   \n",
       "16541    -121.23     37.79                21.0       1922.0           373.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "2072       1397.0       417.0         1.4817             72000.0   \n",
       "10600       862.0       340.0         6.9133            274100.0   \n",
       "2494        931.0       214.0         1.5536             58300.0   \n",
       "4284        597.0       227.0         1.5284            200000.0   \n",
       "16541      1130.0       372.0         4.0815            117900.0   \n",
       "\n",
       "      ocean_proximity  \n",
       "2072           INLAND  \n",
       "10600       <1H OCEAN  \n",
       "2494           INLAND  \n",
       "4284        <1H OCEAN  \n",
       "16541          INLAND  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"data.head()\";\n",
       "                var nbb_formatted_code = \"data.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746cc7e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>-119.84</td>\n",
       "      <td>36.77</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>1.4817</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10600</th>\n",
       "      <td>-117.80</td>\n",
       "      <td>33.68</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2032.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>6.9133</td>\n",
       "      <td>274100.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>-120.19</td>\n",
       "      <td>36.60</td>\n",
       "      <td>25.0</td>\n",
       "      <td>875.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>931.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>1.5536</td>\n",
       "      <td>58300.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>-118.32</td>\n",
       "      <td>34.10</td>\n",
       "      <td>31.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.5284</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16541</th>\n",
       "      <td>-121.23</td>\n",
       "      <td>37.79</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>4.0815</td>\n",
       "      <td>117900.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "2072     -119.84     36.77                 6.0       1853.0           473.0   \n",
       "10600    -117.80     33.68                 8.0       2032.0           349.0   \n",
       "2494     -120.19     36.60                25.0        875.0           214.0   \n",
       "4284     -118.32     34.10                31.0        622.0           229.0   \n",
       "16541    -121.23     37.79                21.0       1922.0           373.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "2072       1397.0       417.0         1.4817             72000.0   \n",
       "10600       862.0       340.0         6.9133            274100.0   \n",
       "2494        931.0       214.0         1.5536             58300.0   \n",
       "4284        597.0       227.0         1.5284            200000.0   \n",
       "16541      1130.0       372.0         4.0815            117900.0   \n",
       "\n",
       "      ocean_proximity  \n",
       "2072           INLAND  \n",
       "10600       <1H OCEAN  \n",
       "2494           INLAND  \n",
       "4284        <1H OCEAN  \n",
       "16541          INLAND  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# data.plot(\\n#     kind=\\\"scatter\\\",\\n#     x=\\\"median_income\\\",\\n#     y=\\\"median_house_value\\\",\\n#     figsize=(10, 7),\\n#     alpha=0.4,\\n# )\\n\\n# data[\\\"total_rooms_per_households\\\"] = data[\\\"total_rooms\\\"] / data[\\\"households\\\"]\\n#\\n# data[\\\"total_bedrooms_per_total_rooms\\\"] = data[\\\"total_bedrooms\\\"] / data[\\\"total_rooms\\\"]\\n\\n# data[\\\"population_per_households\\\"] = data[\\\"population\\\"] / data[\\\"households\\\"]\\n\\ncorr_matrix = data.corr()\\n# print(corr_matrix)\\ncorr_matrix\\n\\n# corr_matrix[\\\"median_house_value\\\"]\\n\\ncorr_matrix[\\\"median_house_value\\\"].sort_values(ascending=False)\\ndata.head()\";\n",
       "                var nbb_formatted_code = \"# data.plot(\\n#     kind=\\\"scatter\\\",\\n#     x=\\\"median_income\\\",\\n#     y=\\\"median_house_value\\\",\\n#     figsize=(10, 7),\\n#     alpha=0.4,\\n# )\\n\\n# data[\\\"total_rooms_per_households\\\"] = data[\\\"total_rooms\\\"] / data[\\\"households\\\"]\\n#\\n# data[\\\"total_bedrooms_per_total_rooms\\\"] = data[\\\"total_bedrooms\\\"] / data[\\\"total_rooms\\\"]\\n\\n# data[\\\"population_per_households\\\"] = data[\\\"population\\\"] / data[\\\"households\\\"]\\n\\ncorr_matrix = data.corr()\\n# print(corr_matrix)\\ncorr_matrix\\n\\n# corr_matrix[\\\"median_house_value\\\"]\\n\\ncorr_matrix[\\\"median_house_value\\\"].sort_values(ascending=False)\\ndata.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data.plot(\n",
    "#     kind=\"scatter\",\n",
    "#     x=\"median_income\",\n",
    "#     y=\"median_house_value\",\n",
    "#     figsize=(10, 7),\n",
    "#     alpha=0.4,\n",
    "# )\n",
    "\n",
    "# data[\"total_rooms_per_households\"] = data[\"total_rooms\"] / data[\"households\"]\n",
    "#\n",
    "# data[\"total_bedrooms_per_total_rooms\"] = data[\"total_bedrooms\"] / data[\"total_rooms\"]\n",
    "\n",
    "# data[\"population_per_households\"] = data[\"population\"] / data[\"households\"]\n",
    "\n",
    "corr_matrix = data.corr()\n",
    "# print(corr_matrix)\n",
    "corr_matrix\n",
    "\n",
    "# corr_matrix[\"median_house_value\"]\n",
    "\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a095ab49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"from sklearn.base import BaseEstimator, TransformerMixin\\n\\n# # ==prapare the data\\n\\n# # numerical data            ===>         missing values\\n# # categorical and text data ===>labelencoder ,onehotencoder\\n# # numerical data            ===> feature scaling\\n# # numerical data            ===> custom transformers\\n\\n# df = train_set.copy()\\n# df_label = df[\\\"median_house_value\\\"].copy()\\n# df=df.drop(\\\"median_house_value\\\", axis=1)\\n# # df.info()\\n\\n\\n# # df_num = df.drop(\\\"ocean_proximity\\\", axis=1)\\n# # df_num.head()\\n\\n# # ==================== simpleImputer\\n# # df_num=df_num.dropna(subset=['total_bedrooms']) #option 1\\n\\n\\n# # df_num.drop('total_bedrooms',axis=1)     #option 2\\n\\n# # optin 3\\n# # use th max or min or meadin or a const number for total_bedrooms\\n\\n# # median = df_num[\\\"total_bedrooms\\\"].median()\\n# # df_num[\\\"total_bedrooms\\\"].fillna(median)\\n# # df_num.info()\\n\\n\\n# imputer = SimpleImputer(missing_values=np.nan, strategy=\\\"median\\\")\\n# imputer.fit(df_num)\\n# X = imputer.transform(df_num)\\n# df_num_imput_er = pd.DataFrame(X, columns=df_num.columns)\\n# # df_num_imput_er.info()\\n# # df_num.info()\\n# # df_num_imput_er.head()\\n\\n\\n# # ========================================custom transformers\\n\\n# rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\\n\\n\\n# class CombineAtteributeAdder(BaseEstimator, TransformerMixin):\\n#     def fit(self, X, y=None):\\n#         return self\\n\\n#     def transform(self, X, y=None):\\n#         rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\\n#         population_per_household = X[:, population_ix] / X[:, household_ix]\\n\\n#         bedrooms_per_rooms = X[:, bedrooms_ix] / X[:, rooms_ix]\\n\\n#         return np.c_[\\n#             X, rooms_per_household, population_per_household, bedrooms_per_rooms\\n#         ]\\n\\n\\n# custom = CombineAtteributeAdder()\\n# data_sustom_tr_tmp = custom.transform(df_num_imput_er.values)\\n\\n# data_sustom_tr = pd.DataFrame(data_sustom_tr_tmp)\\n\\n# columns = list(df_num_imput_er.columns)\\n# columns.append(\\\"rooms_per_household\\\")\\n# columns.append(\\\"population_per_household\\\")\\n# columns.append(\\\"bedrooms_per_rooms\\\")\\n\\n# data_sustom_tr.columns = columns\\n# data_sustom_tr.head(10)\\n# # data_sustom_tr.shape\\n# # data.shape\\n\\n# # =============================================feature scaling===================================\\n\\n# data_sustom_tr.describe()\\n\\n\\n# feature_scal = StandardScaler()\\n# data_num_scaled_tr = pd.DataFrame(\\n#     feature_scal.fit_transform(data_sustom_tr.values), columns=data_sustom_tr.columns\\n# )\\n\\n\\n# data_num_scaled_tr.head()\\n# # ==============================Lable Encoder=============================================\\n# # LableEncoder\\n# from sklearn.preprocessing import LabelEncoder\\n\\n\\n# # encoder=LabelEncoder()\\n# # data_cat=df['ocean_proximity']\\n# # data_cat_encoded=encoder.fit_transform(data_cat)\\n# # data_cat_encoded=pd.DataFrame(data_cat_encoded,columns=['ocean_proximity'])\\n# # data_cat_encoded.head()\\n\\n# # =============================================onehotEncoder ==================\\n\\n# from sklearn.preprocessing import OneHotEncoder\\n\\n# encoder_1hot = OneHotEncoder(sparse=False)\\n# data_cat_1hot_tmp = encoder_1hot.fit_transform(df[[\\\"ocean_proximity\\\"]])\\n\\n# data_cat_1hot = pd.DataFrame(data_cat_1hot_tmp)\\n# data_cat_1hot.columns = encoder_1hot.get_feature_names([\\\"prox\\\"])\\n\\n# data_cat_1hot.head()\\n\\n# # ======================\\n# final = pd.concat([data_num_scaled_tr, data_cat_1hot], axis=1)\\n# final.head()\";\n",
       "                var nbb_formatted_code = \"from sklearn.base import BaseEstimator, TransformerMixin\\n\\n# # ==prapare the data\\n\\n# # numerical data            ===>         missing values\\n# # categorical and text data ===>labelencoder ,onehotencoder\\n# # numerical data            ===> feature scaling\\n# # numerical data            ===> custom transformers\\n\\n# df = train_set.copy()\\n# df_label = df[\\\"median_house_value\\\"].copy()\\n# df=df.drop(\\\"median_house_value\\\", axis=1)\\n# # df.info()\\n\\n\\n# # df_num = df.drop(\\\"ocean_proximity\\\", axis=1)\\n# # df_num.head()\\n\\n# # ==================== simpleImputer\\n# # df_num=df_num.dropna(subset=['total_bedrooms']) #option 1\\n\\n\\n# # df_num.drop('total_bedrooms',axis=1)     #option 2\\n\\n# # optin 3\\n# # use th max or min or meadin or a const number for total_bedrooms\\n\\n# # median = df_num[\\\"total_bedrooms\\\"].median()\\n# # df_num[\\\"total_bedrooms\\\"].fillna(median)\\n# # df_num.info()\\n\\n\\n# imputer = SimpleImputer(missing_values=np.nan, strategy=\\\"median\\\")\\n# imputer.fit(df_num)\\n# X = imputer.transform(df_num)\\n# df_num_imput_er = pd.DataFrame(X, columns=df_num.columns)\\n# # df_num_imput_er.info()\\n# # df_num.info()\\n# # df_num_imput_er.head()\\n\\n\\n# # ========================================custom transformers\\n\\n# rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\\n\\n\\n# class CombineAtteributeAdder(BaseEstimator, TransformerMixin):\\n#     def fit(self, X, y=None):\\n#         return self\\n\\n#     def transform(self, X, y=None):\\n#         rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\\n#         population_per_household = X[:, population_ix] / X[:, household_ix]\\n\\n#         bedrooms_per_rooms = X[:, bedrooms_ix] / X[:, rooms_ix]\\n\\n#         return np.c_[\\n#             X, rooms_per_household, population_per_household, bedrooms_per_rooms\\n#         ]\\n\\n\\n# custom = CombineAtteributeAdder()\\n# data_sustom_tr_tmp = custom.transform(df_num_imput_er.values)\\n\\n# data_sustom_tr = pd.DataFrame(data_sustom_tr_tmp)\\n\\n# columns = list(df_num_imput_er.columns)\\n# columns.append(\\\"rooms_per_household\\\")\\n# columns.append(\\\"population_per_household\\\")\\n# columns.append(\\\"bedrooms_per_rooms\\\")\\n\\n# data_sustom_tr.columns = columns\\n# data_sustom_tr.head(10)\\n# # data_sustom_tr.shape\\n# # data.shape\\n\\n# # =============================================feature scaling===================================\\n\\n# data_sustom_tr.describe()\\n\\n\\n# feature_scal = StandardScaler()\\n# data_num_scaled_tr = pd.DataFrame(\\n#     feature_scal.fit_transform(data_sustom_tr.values), columns=data_sustom_tr.columns\\n# )\\n\\n\\n# data_num_scaled_tr.head()\\n# # ==============================Lable Encoder=============================================\\n# # LableEncoder\\n# from sklearn.preprocessing import LabelEncoder\\n\\n\\n# # encoder=LabelEncoder()\\n# # data_cat=df['ocean_proximity']\\n# # data_cat_encoded=encoder.fit_transform(data_cat)\\n# # data_cat_encoded=pd.DataFrame(data_cat_encoded,columns=['ocean_proximity'])\\n# # data_cat_encoded.head()\\n\\n# # =============================================onehotEncoder ==================\\n\\n# from sklearn.preprocessing import OneHotEncoder\\n\\n# encoder_1hot = OneHotEncoder(sparse=False)\\n# data_cat_1hot_tmp = encoder_1hot.fit_transform(df[[\\\"ocean_proximity\\\"]])\\n\\n# data_cat_1hot = pd.DataFrame(data_cat_1hot_tmp)\\n# data_cat_1hot.columns = encoder_1hot.get_feature_names([\\\"prox\\\"])\\n\\n# data_cat_1hot.head()\\n\\n# # ======================\\n# final = pd.concat([data_num_scaled_tr, data_cat_1hot], axis=1)\\n# final.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# # ==prapare the data\n",
    "\n",
    "# # numerical data            ===>         missing values\n",
    "# # categorical and text data ===>labelencoder ,onehotencoder\n",
    "# # numerical data            ===> feature scaling\n",
    "# # numerical data            ===> custom transformers\n",
    "\n",
    "# df = train_set.copy()\n",
    "# df_label = df[\"median_house_value\"].copy()\n",
    "# df=df.drop(\"median_house_value\", axis=1)\n",
    "# # df.info()\n",
    "\n",
    "\n",
    "# # df_num = df.drop(\"ocean_proximity\", axis=1)\n",
    "# # df_num.head()\n",
    "\n",
    "# # ==================== simpleImputer\n",
    "# # df_num=df_num.dropna(subset=['total_bedrooms']) #option 1\n",
    "\n",
    "\n",
    "# # df_num.drop('total_bedrooms',axis=1)     #option 2\n",
    "\n",
    "# # optin 3\n",
    "# # use th max or min or meadin or a const number for total_bedrooms\n",
    "\n",
    "# # median = df_num[\"total_bedrooms\"].median()\n",
    "# # df_num[\"total_bedrooms\"].fillna(median)\n",
    "# # df_num.info()\n",
    "\n",
    "\n",
    "# imputer = SimpleImputer(missing_values=np.nan, strategy=\"median\")\n",
    "# imputer.fit(df_num)\n",
    "# X = imputer.transform(df_num)\n",
    "# df_num_imput_er = pd.DataFrame(X, columns=df_num.columns)\n",
    "# # df_num_imput_er.info()\n",
    "# # df_num.info()\n",
    "# # df_num_imput_er.head()\n",
    "\n",
    "\n",
    "# # ========================================custom transformers\n",
    "\n",
    "# rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n",
    "\n",
    "\n",
    "# class CombineAtteributeAdder(BaseEstimator, TransformerMixin):\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X, y=None):\n",
    "#         rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "#         population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "\n",
    "#         bedrooms_per_rooms = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "\n",
    "#         return np.c_[\n",
    "#             X, rooms_per_household, population_per_household, bedrooms_per_rooms\n",
    "#         ]\n",
    "\n",
    "\n",
    "# custom = CombineAtteributeAdder()\n",
    "# data_sustom_tr_tmp = custom.transform(df_num_imput_er.values)\n",
    "\n",
    "# data_sustom_tr = pd.DataFrame(data_sustom_tr_tmp)\n",
    "\n",
    "# columns = list(df_num_imput_er.columns)\n",
    "# columns.append(\"rooms_per_household\")\n",
    "# columns.append(\"population_per_household\")\n",
    "# columns.append(\"bedrooms_per_rooms\")\n",
    "\n",
    "# data_sustom_tr.columns = columns\n",
    "# data_sustom_tr.head(10)\n",
    "# # data_sustom_tr.shape\n",
    "# # data.shape\n",
    "\n",
    "# # =============================================feature scaling===================================\n",
    "\n",
    "# data_sustom_tr.describe()\n",
    "\n",
    "\n",
    "# feature_scal = StandardScaler()\n",
    "# data_num_scaled_tr = pd.DataFrame(\n",
    "#     feature_scal.fit_transform(data_sustom_tr.values), columns=data_sustom_tr.columns\n",
    "# )\n",
    "\n",
    "\n",
    "# data_num_scaled_tr.head()\n",
    "# # ==============================Lable Encoder=============================================\n",
    "# # LableEncoder\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# # encoder=LabelEncoder()\n",
    "# # data_cat=df['ocean_proximity']\n",
    "# # data_cat_encoded=encoder.fit_transform(data_cat)\n",
    "# # data_cat_encoded=pd.DataFrame(data_cat_encoded,columns=['ocean_proximity'])\n",
    "# # data_cat_encoded.head()\n",
    "\n",
    "# # =============================================onehotEncoder ==================\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# encoder_1hot = OneHotEncoder(sparse=False)\n",
    "# data_cat_1hot_tmp = encoder_1hot.fit_transform(df[[\"ocean_proximity\"]])\n",
    "\n",
    "# data_cat_1hot = pd.DataFrame(data_cat_1hot_tmp)\n",
    "# data_cat_1hot.columns = encoder_1hot.get_feature_names([\"prox\"])\n",
    "\n",
    "# data_cat_1hot.head()\n",
    "\n",
    "# # ======================\n",
    "# final = pd.concat([data_num_scaled_tr, data_cat_1hot], axis=1)\n",
    "# final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3128aeed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>rooms_per_household</th>\n",
       "      <th>population_per_household</th>\n",
       "      <th>bedrooms_per_rooms</th>\n",
       "      <th>prox_&lt;1H OCEAN</th>\n",
       "      <th>prox_INLAND</th>\n",
       "      <th>prox_ISLAND</th>\n",
       "      <th>prox_NEAR BAY</th>\n",
       "      <th>prox_NEAR OCEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.137635</td>\n",
       "      <td>0.534564</td>\n",
       "      <td>-1.795939</td>\n",
       "      <td>-0.357368</td>\n",
       "      <td>-0.154134</td>\n",
       "      <td>-0.032827</td>\n",
       "      <td>-0.218173</td>\n",
       "      <td>-1.258403</td>\n",
       "      <td>-0.425185</td>\n",
       "      <td>0.024660</td>\n",
       "      <td>0.658887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.879836</td>\n",
       "      <td>-0.909979</td>\n",
       "      <td>-1.637178</td>\n",
       "      <td>-0.276515</td>\n",
       "      <td>-0.447238</td>\n",
       "      <td>-0.494784</td>\n",
       "      <td>-0.417841</td>\n",
       "      <td>1.610623</td>\n",
       "      <td>0.247344</td>\n",
       "      <td>-0.049867</td>\n",
       "      <td>-0.669911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.312201</td>\n",
       "      <td>0.455091</td>\n",
       "      <td>-0.287715</td>\n",
       "      <td>-0.799127</td>\n",
       "      <td>-0.766343</td>\n",
       "      <td>-0.435204</td>\n",
       "      <td>-0.744572</td>\n",
       "      <td>-1.220425</td>\n",
       "      <td>-0.580880</td>\n",
       "      <td>0.116155</td>\n",
       "      <td>0.488784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.620480</td>\n",
       "      <td>-0.713633</td>\n",
       "      <td>0.188566</td>\n",
       "      <td>-0.913406</td>\n",
       "      <td>-0.730887</td>\n",
       "      <td>-0.723603</td>\n",
       "      <td>-0.710862</td>\n",
       "      <td>-1.233736</td>\n",
       "      <td>-1.172623</td>\n",
       "      <td>-0.041209</td>\n",
       "      <td>2.455426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.830911</td>\n",
       "      <td>1.011403</td>\n",
       "      <td>-0.605236</td>\n",
       "      <td>-0.326201</td>\n",
       "      <td>-0.390508</td>\n",
       "      <td>-0.263373</td>\n",
       "      <td>-0.334862</td>\n",
       "      <td>0.114837</td>\n",
       "      <td>-0.107958</td>\n",
       "      <td>-0.003921</td>\n",
       "      <td>-0.314810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0  -0.137635  0.534564           -1.795939    -0.357368       -0.154134   \n",
       "1   0.879836 -0.909979           -1.637178    -0.276515       -0.447238   \n",
       "2  -0.312201  0.455091           -0.287715    -0.799127       -0.766343   \n",
       "3   0.620480 -0.713633            0.188566    -0.913406       -0.730887   \n",
       "4  -0.830911  1.011403           -0.605236    -0.326201       -0.390508   \n",
       "\n",
       "   population  households  median_income  rooms_per_household  \\\n",
       "0   -0.032827   -0.218173      -1.258403            -0.425185   \n",
       "1   -0.494784   -0.417841       1.610623             0.247344   \n",
       "2   -0.435204   -0.744572      -1.220425            -0.580880   \n",
       "3   -0.723603   -0.710862      -1.233736            -1.172623   \n",
       "4   -0.263373   -0.334862       0.114837            -0.107958   \n",
       "\n",
       "   population_per_household  bedrooms_per_rooms  prox_<1H OCEAN  prox_INLAND  \\\n",
       "0                  0.024660            0.658887             0.0          1.0   \n",
       "1                 -0.049867           -0.669911             1.0          0.0   \n",
       "2                  0.116155            0.488784             0.0          1.0   \n",
       "3                 -0.041209            2.455426             1.0          0.0   \n",
       "4                 -0.003921           -0.314810             0.0          1.0   \n",
       "\n",
       "   prox_ISLAND  prox_NEAR BAY  prox_NEAR OCEAN  \n",
       "0          0.0            0.0              0.0  \n",
       "1          0.0            0.0              0.0  \n",
       "2          0.0            0.0              0.0  \n",
       "3          0.0            0.0              0.0  \n",
       "4          0.0            0.0              0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# \\u0645\\u0627 \\u0647\\u0631\\u0622\\u0646\\u0686\\u0647 \\u06a9\\u0647 \\u062f\\u0631 \\u0645\\u0631\\u062d\\u0644\\u0647 \\u0642\\u0628\\u0644 \\u0627\\u0646\\u062c\\u0627\\u0645 \\u062f\\u0627\\u062f\\u06cc\\u0645 \\u0628\\u0631\\u0627\\u06cc \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627\\u06cc \\u0627\\u0645\\u0648\\u0632\\u0634\\u06cc \\u0628\\u0648\\u062f\\n# \\u062d\\u0627\\u0644 \\u0627\\u06af\\u0631 \\u062f\\u0627\\u062f\\u0647 \\u0627\\u06cc \\u062f\\u06cc\\u06af\\u0631\\u06cc \\u0628\\u0647 \\u0645\\u0627 \\u0627\\u0636\\u0627\\u0636\\u0641\\u0647 \\u0628\\u0634\\u0647 \\u0648 \\u0647\\u0645\\u0627\\u0648\\u0646 \\u062f\\u0627\\u062f\\u0647\\u0627 \\u06a9\\u0647 \\u0628\\u0631\\u0627\\u0633 \\u062a\\u0633\\u062a \\u062c\\u062f\\u0627\\u06a9\\u0631\\u062f\\u06cc\\u0645 \\u0631\\u0648 \\u0628\\u0627\\u06cc\\u062f \\u0647\\u0645\\u06cc\\u0646 \\u06a9\\u0627\\u0631\\n# \\u0647\\u0627 \\u0631\\u0627 \\u0628\\u0631\\u0627\\u0634 \\u0627\\u0646\\u062c\\u0627\\u0645 \\u0628\\u062f\\u06cc\\u0645 \\u06cc\\u06a9 \\u0631\\u0627\\u0647\\u0634 \\u0627\\u06cc\\u0646\\u0647 \\u0627\\u0632 \\u0647\\u0645\\u0648\\u0646 \\u0631\\u0648\\u0634 \\u0628\\u0627\\u0644\\u0627 \\u0628\\u0631\\u06cc\\u0645 \\u0628\\u0631\\u0627\\u06cc \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627\\u06cc \\u062f\\u06cc\\u06af\\u0647 \\u0631\\u0627\\u0647 \\u062f\\u06cc\\u06af\\u0647 \\u0627\\u0633\\u062a\\u0641\\u0627\\u062f\\u0647 \\u0627\\u0632\\n# \\u067e\\u0627\\u06cc\\u067e \\u0644\\u0627\\u06cc\\u0646 \\u0627\\u0633\\u062a.\\n\\n# \\u067e\\u0627\\u067e\\u06cc\\u067e \\u0644\\u0627\\u06cc\\u0646 \\u0686\\u06cc\\u0647\\u061f\\n# \\u0645\\u06cc\\u06af\\u0647 \\u06af\\u0631\\u0648\\u0647\\u06cc \\u0627\\u0632 \\u062f\\u0633\\u062a\\u0648\\u0631 \\u0647\\u0627 \\u0631\\u0648 \\u0628\\u0647 \\u0627\\u06cc\\u0646 \\u062a\\u0631\\u062a\\u06cc\\u0628\\u06cc \\u06a9\\u0647 \\u0645\\u0646 \\u0645\\u06cc\\u062f\\u0645 \\u0627\\u062c\\u0631\\u0627 \\u06a9\\u0646\\n\\n\\n# \\u0645\\u0631\\u062d\\u0644\\u0647 \\u06f4 \\u0628\\u0627\\n# pipline principles\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.base import BaseEstimator, TransformerMixin\\nfrom sklearn.pipeline import FeatureUnion\\n\\nrooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\\n\\n\\nclass CombineAtteributeAdder(BaseEstimator, TransformerMixin):\\n    def fit(self, X, y=None):\\n        return self\\n\\n    def transform(self, X, y=None):\\n        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\\n        population_per_household = X[:, population_ix] / X[:, household_ix]\\n\\n        bedrooms_per_rooms = X[:, bedrooms_ix] / X[:, rooms_ix]\\n\\n        return np.c_[\\n            X, rooms_per_household, population_per_household, bedrooms_per_rooms\\n        ]\\n\\n\\n# \\u06a9\\u0644\\u0627\\u0633 \\u067e\\u0627\\u06cc\\u06cc\\u0646  \\u0642\\u0631\\u0627\\u0631 \\u0627\\u0633\\u062a \\u06a9\\u0644 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627 \\u0631\\u0648 \\u06a9\\u0647 \\u0628\\u0647\\u0634 \\u0645\\u06cc\\u062f\\u06cc\\u0645\\n# \\u0633\\u062a\\u0648\\u0646 \\u0647\\u0627\\u06cc \\u0645\\u062f\\u0646\\u0638\\u0631 \\u0631\\u0648 \\u0627\\u0632\\u0634 \\u0628\\u06a9\\u0634\\u0647 \\u0628\\u06cc\\u0631\\u0648\\u0646\\n# \\u0645\\u062b\\u0644\\u0627 \\u0628\\u06cc\\u0627\\u062f \\u0633\\u062a\\u0648\\u0646 \\u0647\\u0627\\u06cc \\u0639\\u062f\\u062f\\u06cc \\u0648 \\u063a\\u06cc\\u0631 \\u0639\\u062f\\u062f\\u06cc \\u0631\\u0648 \\u0628\\u0631\\u0627\\u06cc \\u0645\\u0627 \\u062c\\u062f\\u0627 \\u06a9\\u0646\\u0647\\n\\n\\nclass DataFrameSelector(BaseEstimator, TransformerMixin):\\n    def __init__(self, attribute_names):\\n        self.attribute_names = attribute_names\\n\\n    def fit(self, X, y=None):\\n        return self\\n\\n    def transform(self, X):\\n        return X[self.attribute_names].values\\n\\n\\ndf = train_set.copy()\\ndf_label = df[\\\"median_house_value\\\"].copy()\\ndf=df.drop(\\\"median_house_value\\\", axis=1)\\n# df.info()\\n\\ndf_num = df.drop([\\\"ocean_proximity\\\"], axis=1)\\nnum_attrs = list(df_num)\\ncat_attrs = [\\\"ocean_proximity\\\"]\\n\\n\\nnum_pipline = Pipeline(\\n    [\\n        #      \\u0627\\u0632\\u06a9\\u0644 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627 \\u0641\\u0642\\u0637 \\u0627\\u0648\\u0646 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627\\u06cc\\u06cc \\u06a9\\u0647 \\u0633\\u062a\\u0648\\u0646 \\u0647\\u0627\\u06cc\\u06cc \\u0639\\u062f\\u062f\\u06cc \\u0647\\u0633\\u062a\\u0646 \\u0631\\u0648 \\u0645\\u06cc\\u06a9\\u0634\\u0647 \\u0628\\u06cc\\u0631\\u0648\\u0646\\n        (\\\"selector\\\", DataFrameSelector(num_attrs)),\\n        #         \\u0628\\u0639\\u062f \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627\\u06cc \\u0646\\u0627\\u0644 \\u0631\\u0648 \\u062f\\u0631\\u0633\\u062a \\u0645\\u06cc\\u06a9\\u0646\\u0647\\n        (\\\"imputer\\\", SimpleImputer(missing_values=np.nan, strategy=\\\"median\\\")),\\n        #         \\u062f\\u0627\\u062f\\u0647\\u0627\\u06cc \\u062c\\u062f\\u06cc\\u062f \\u06a9\\u0647 \\u0633\\u0627\\u062e\\u062a\\u06cc\\u0645 \\u0631\\u0648 \\u0627\\u0636\\u0627\\u0641\\u0647 \\u0645\\u06cc\\u06a9\\u0646\\u06cc\\u0645\\n        (\\\"attribs_adder\\\", CombineAtteributeAdder()),\\n        #         \\u0645\\u0642\\u06cc\\u0627\\u0633 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627 \\u0631\\u0648 \\u062f\\u0631\\u0633\\u062a \\u0645\\u06cc\\u06a9\\u0646\\u06cc\\u0645\\n        (\\\"std_scaler\\\", StandardScaler()),\\n    ]\\n)\\n\\ncat_pipline = Pipeline(\\n    [\\n        (\\\"selector\\\", DataFrameSelector(cat_attrs)),\\n        (\\\"one_hot_encoder\\\", OneHotEncoder(sparse=False)),\\n    ]\\n)\\n\\n\\nfull_pipline = FeatureUnion(\\n    transformer_list=[\\n        (\\\"num_pipline\\\", num_pipline),\\n        (\\\"cat_pipline\\\", cat_pipline),\\n    ]\\n)\\ndf.columns\\nhousing_prepared = full_pipline.fit_transform(df)\\nhousing_prepared_df = pd.DataFrame(\\n    housing_prepared,\\n    columns=[\\n        \\\"longitude\\\",\\n        \\\"latitude\\\",\\n        \\\"housing_median_age\\\",\\n        \\\"total_rooms\\\",\\n        \\\"total_bedrooms\\\",\\n        \\\"population\\\",\\n        \\\"households\\\",\\n        \\\"median_income\\\",\\n        \\\"rooms_per_household\\\",\\n        \\\"population_per_household\\\",\\n        \\\"bedrooms_per_rooms\\\",\\n        \\\"prox_<1H OCEAN\\\",\\n        \\\"prox_INLAND\\\",\\n        \\\"prox_ISLAND\\\",\\n        \\\"prox_NEAR BAY\\\",\\n        \\\"prox_NEAR OCEAN\\\",\\n    ],\\n)\\nhousing_prepared_df.head()\";\n",
       "                var nbb_formatted_code = \"# \\u0645\\u0627 \\u0647\\u0631\\u0622\\u0646\\u0686\\u0647 \\u06a9\\u0647 \\u062f\\u0631 \\u0645\\u0631\\u062d\\u0644\\u0647 \\u0642\\u0628\\u0644 \\u0627\\u0646\\u062c\\u0627\\u0645 \\u062f\\u0627\\u062f\\u06cc\\u0645 \\u0628\\u0631\\u0627\\u06cc \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627\\u06cc \\u0627\\u0645\\u0648\\u0632\\u0634\\u06cc \\u0628\\u0648\\u062f\\n# \\u062d\\u0627\\u0644 \\u0627\\u06af\\u0631 \\u062f\\u0627\\u062f\\u0647 \\u0627\\u06cc \\u062f\\u06cc\\u06af\\u0631\\u06cc \\u0628\\u0647 \\u0645\\u0627 \\u0627\\u0636\\u0627\\u0636\\u0641\\u0647 \\u0628\\u0634\\u0647 \\u0648 \\u0647\\u0645\\u0627\\u0648\\u0646 \\u062f\\u0627\\u062f\\u0647\\u0627 \\u06a9\\u0647 \\u0628\\u0631\\u0627\\u0633 \\u062a\\u0633\\u062a \\u062c\\u062f\\u0627\\u06a9\\u0631\\u062f\\u06cc\\u0645 \\u0631\\u0648 \\u0628\\u0627\\u06cc\\u062f \\u0647\\u0645\\u06cc\\u0646 \\u06a9\\u0627\\u0631\\n# \\u0647\\u0627 \\u0631\\u0627 \\u0628\\u0631\\u0627\\u0634 \\u0627\\u0646\\u062c\\u0627\\u0645 \\u0628\\u062f\\u06cc\\u0645 \\u06cc\\u06a9 \\u0631\\u0627\\u0647\\u0634 \\u0627\\u06cc\\u0646\\u0647 \\u0627\\u0632 \\u0647\\u0645\\u0648\\u0646 \\u0631\\u0648\\u0634 \\u0628\\u0627\\u0644\\u0627 \\u0628\\u0631\\u06cc\\u0645 \\u0628\\u0631\\u0627\\u06cc \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627\\u06cc \\u062f\\u06cc\\u06af\\u0647 \\u0631\\u0627\\u0647 \\u062f\\u06cc\\u06af\\u0647 \\u0627\\u0633\\u062a\\u0641\\u0627\\u062f\\u0647 \\u0627\\u0632\\n# \\u067e\\u0627\\u06cc\\u067e \\u0644\\u0627\\u06cc\\u0646 \\u0627\\u0633\\u062a.\\n\\n# \\u067e\\u0627\\u067e\\u06cc\\u067e \\u0644\\u0627\\u06cc\\u0646 \\u0686\\u06cc\\u0647\\u061f\\n# \\u0645\\u06cc\\u06af\\u0647 \\u06af\\u0631\\u0648\\u0647\\u06cc \\u0627\\u0632 \\u062f\\u0633\\u062a\\u0648\\u0631 \\u0647\\u0627 \\u0631\\u0648 \\u0628\\u0647 \\u0627\\u06cc\\u0646 \\u062a\\u0631\\u062a\\u06cc\\u0628\\u06cc \\u06a9\\u0647 \\u0645\\u0646 \\u0645\\u06cc\\u062f\\u0645 \\u0627\\u062c\\u0631\\u0627 \\u06a9\\u0646\\n\\n\\n# \\u0645\\u0631\\u062d\\u0644\\u0647 \\u06f4 \\u0628\\u0627\\n# pipline principles\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.base import BaseEstimator, TransformerMixin\\nfrom sklearn.pipeline import FeatureUnion\\n\\nrooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\\n\\n\\nclass CombineAtteributeAdder(BaseEstimator, TransformerMixin):\\n    def fit(self, X, y=None):\\n        return self\\n\\n    def transform(self, X, y=None):\\n        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\\n        population_per_household = X[:, population_ix] / X[:, household_ix]\\n\\n        bedrooms_per_rooms = X[:, bedrooms_ix] / X[:, rooms_ix]\\n\\n        return np.c_[\\n            X, rooms_per_household, population_per_household, bedrooms_per_rooms\\n        ]\\n\\n\\n# \\u06a9\\u0644\\u0627\\u0633 \\u067e\\u0627\\u06cc\\u06cc\\u0646  \\u0642\\u0631\\u0627\\u0631 \\u0627\\u0633\\u062a \\u06a9\\u0644 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627 \\u0631\\u0648 \\u06a9\\u0647 \\u0628\\u0647\\u0634 \\u0645\\u06cc\\u062f\\u06cc\\u0645\\n# \\u0633\\u062a\\u0648\\u0646 \\u0647\\u0627\\u06cc \\u0645\\u062f\\u0646\\u0638\\u0631 \\u0631\\u0648 \\u0627\\u0632\\u0634 \\u0628\\u06a9\\u0634\\u0647 \\u0628\\u06cc\\u0631\\u0648\\u0646\\n# \\u0645\\u062b\\u0644\\u0627 \\u0628\\u06cc\\u0627\\u062f \\u0633\\u062a\\u0648\\u0646 \\u0647\\u0627\\u06cc \\u0639\\u062f\\u062f\\u06cc \\u0648 \\u063a\\u06cc\\u0631 \\u0639\\u062f\\u062f\\u06cc \\u0631\\u0648 \\u0628\\u0631\\u0627\\u06cc \\u0645\\u0627 \\u062c\\u062f\\u0627 \\u06a9\\u0646\\u0647\\n\\n\\nclass DataFrameSelector(BaseEstimator, TransformerMixin):\\n    def __init__(self, attribute_names):\\n        self.attribute_names = attribute_names\\n\\n    def fit(self, X, y=None):\\n        return self\\n\\n    def transform(self, X):\\n        return X[self.attribute_names].values\\n\\n\\ndf = train_set.copy()\\ndf_label = df[\\\"median_house_value\\\"].copy()\\ndf = df.drop(\\\"median_house_value\\\", axis=1)\\n# df.info()\\n\\ndf_num = df.drop([\\\"ocean_proximity\\\"], axis=1)\\nnum_attrs = list(df_num)\\ncat_attrs = [\\\"ocean_proximity\\\"]\\n\\n\\nnum_pipline = Pipeline(\\n    [\\n        #      \\u0627\\u0632\\u06a9\\u0644 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627 \\u0641\\u0642\\u0637 \\u0627\\u0648\\u0646 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627\\u06cc\\u06cc \\u06a9\\u0647 \\u0633\\u062a\\u0648\\u0646 \\u0647\\u0627\\u06cc\\u06cc \\u0639\\u062f\\u062f\\u06cc \\u0647\\u0633\\u062a\\u0646 \\u0631\\u0648 \\u0645\\u06cc\\u06a9\\u0634\\u0647 \\u0628\\u06cc\\u0631\\u0648\\u0646\\n        (\\\"selector\\\", DataFrameSelector(num_attrs)),\\n        #         \\u0628\\u0639\\u062f \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627\\u06cc \\u0646\\u0627\\u0644 \\u0631\\u0648 \\u062f\\u0631\\u0633\\u062a \\u0645\\u06cc\\u06a9\\u0646\\u0647\\n        (\\\"imputer\\\", SimpleImputer(missing_values=np.nan, strategy=\\\"median\\\")),\\n        #         \\u062f\\u0627\\u062f\\u0647\\u0627\\u06cc \\u062c\\u062f\\u06cc\\u062f \\u06a9\\u0647 \\u0633\\u0627\\u062e\\u062a\\u06cc\\u0645 \\u0631\\u0648 \\u0627\\u0636\\u0627\\u0641\\u0647 \\u0645\\u06cc\\u06a9\\u0646\\u06cc\\u0645\\n        (\\\"attribs_adder\\\", CombineAtteributeAdder()),\\n        #         \\u0645\\u0642\\u06cc\\u0627\\u0633 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627 \\u0631\\u0648 \\u062f\\u0631\\u0633\\u062a \\u0645\\u06cc\\u06a9\\u0646\\u06cc\\u0645\\n        (\\\"std_scaler\\\", StandardScaler()),\\n    ]\\n)\\n\\ncat_pipline = Pipeline(\\n    [\\n        (\\\"selector\\\", DataFrameSelector(cat_attrs)),\\n        (\\\"one_hot_encoder\\\", OneHotEncoder(sparse=False)),\\n    ]\\n)\\n\\n\\nfull_pipline = FeatureUnion(\\n    transformer_list=[\\n        (\\\"num_pipline\\\", num_pipline),\\n        (\\\"cat_pipline\\\", cat_pipline),\\n    ]\\n)\\ndf.columns\\nhousing_prepared = full_pipline.fit_transform(df)\\nhousing_prepared_df = pd.DataFrame(\\n    housing_prepared,\\n    columns=[\\n        \\\"longitude\\\",\\n        \\\"latitude\\\",\\n        \\\"housing_median_age\\\",\\n        \\\"total_rooms\\\",\\n        \\\"total_bedrooms\\\",\\n        \\\"population\\\",\\n        \\\"households\\\",\\n        \\\"median_income\\\",\\n        \\\"rooms_per_household\\\",\\n        \\\"population_per_household\\\",\\n        \\\"bedrooms_per_rooms\\\",\\n        \\\"prox_<1H OCEAN\\\",\\n        \\\"prox_INLAND\\\",\\n        \\\"prox_ISLAND\\\",\\n        \\\"prox_NEAR BAY\\\",\\n        \\\"prox_NEAR OCEAN\\\",\\n    ],\\n)\\nhousing_prepared_df.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ما هرآنچه که در مرحله قبل انجام دادیم برای داده های اموزشی بود\n",
    "# حال اگر داده ای دیگری به ما اضاضفه بشه و هماون دادها که براس تست جداکردیم رو باید همین کار\n",
    "# ها را براش انجام بدیم یک راهش اینه از همون روش بالا بریم برای داده های دیگه راه دیگه استفاده از\n",
    "# پایپ لاین است.\n",
    "\n",
    "# پاپیپ لاین چیه؟\n",
    "# میگه گروهی از دستور ها رو به این ترتیبی که من میدم اجرا کن\n",
    "\n",
    "\n",
    "# مرحله ۴ با\n",
    "# pipline principles\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n",
    "\n",
    "\n",
    "class CombineAtteributeAdder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "\n",
    "        bedrooms_per_rooms = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "\n",
    "        return np.c_[\n",
    "            X, rooms_per_household, population_per_household, bedrooms_per_rooms\n",
    "        ]\n",
    "\n",
    "\n",
    "# کلاس پایین  قرار است کل داده ها رو که بهش میدیم\n",
    "# ستون های مدنظر رو ازش بکشه بیرون\n",
    "# مثلا بیاد ستون های عددی و غیر عددی رو برای ما جدا کنه\n",
    "\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "\n",
    "df = train_set.copy()\n",
    "df_label = df[\"median_house_value\"].copy()\n",
    "df=df.drop(\"median_house_value\", axis=1)\n",
    "# df.info()\n",
    "\n",
    "df_num = df.drop([\"ocean_proximity\"], axis=1)\n",
    "num_attrs = list(df_num)\n",
    "cat_attrs = [\"ocean_proximity\"]\n",
    "\n",
    "\n",
    "num_pipline = Pipeline(\n",
    "    [\n",
    "        #      ازکل داده ها فقط اون داده هایی که ستون هایی عددی هستن رو میکشه بیرون\n",
    "        (\"selector\", DataFrameSelector(num_attrs)),\n",
    "        #         بعد داده های نال رو درست میکنه\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"median\")),\n",
    "        #         دادهای جدید که ساختیم رو اضافه میکنیم\n",
    "        (\"attribs_adder\", CombineAtteributeAdder()),\n",
    "        #         مقیاس داده ها رو درست میکنیم\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cat_pipline = Pipeline(\n",
    "    [\n",
    "        (\"selector\", DataFrameSelector(cat_attrs)),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(sparse=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "full_pipline = FeatureUnion(\n",
    "    transformer_list=[\n",
    "        (\"num_pipline\", num_pipline),\n",
    "        (\"cat_pipline\", cat_pipline),\n",
    "    ]\n",
    ")\n",
    "df.columns\n",
    "housing_prepared = full_pipline.fit_transform(df)\n",
    "housing_prepared_df = pd.DataFrame(\n",
    "    housing_prepared,\n",
    "    columns=[\n",
    "        \"longitude\",\n",
    "        \"latitude\",\n",
    "        \"housing_median_age\",\n",
    "        \"total_rooms\",\n",
    "        \"total_bedrooms\",\n",
    "        \"population\",\n",
    "        \"households\",\n",
    "        \"median_income\",\n",
    "        \"rooms_per_household\",\n",
    "        \"population_per_household\",\n",
    "        \"bedrooms_per_rooms\",\n",
    "        \"prox_<1H OCEAN\",\n",
    "        \"prox_INLAND\",\n",
    "        \"prox_ISLAND\",\n",
    "        \"prox_NEAR BAY\",\n",
    "        \"prox_NEAR OCEAN\",\n",
    "    ],\n",
    ")\n",
    "housing_prepared_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4675b06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:\t ['35948.1', '315970.8', '61237.9', '152762.0']\n",
      "labbels:\t [72000.0, 274100.0, 58300.0, 200000.0]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# step 5 :\\n# \\u062f\\u0631 \\u0627\\u06cc\\u0646 \\u0645\\u0631\\u062d\\u0644\\u0647 \\u0628\\u0627\\u06cc\\u062f \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\u0647\\u0627\\u06cc \\u0631\\u06af\\u0631\\u0633\\u06cc\\u0648\\u0646 \\u0645\\u062e\\u062a\\u0644\\u0641 \\u0631\\u0648 \\u062a\\u0633\\u062a \\u06a9\\u0646\\u06cc\\u0645\\n\\n# \\u0627\\u0648\\u0644\\u06cc\\u0646 \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\n# \\u0644\\u06cc\\u0646\\u0646\\u06cc\\u0631 \\u0631\\u06af\\u0631\\u0633\\u06cc\\u0648\\u0646\\nfrom sklearn.linear_model import LinearRegression\\n\\n# \\u0627\\u0648\\u0644\\u06cc\\u0646 \\u06a9\\u0627\\u0631\\u06cc \\u06a9\\u0647 \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\u0645\\u0627 \\u0628\\u0627\\u06cc\\u062f \\u0628\\u06a9\\u0646\\u0647 \\u0627\\u06cc\\u0646\\u0647 \\u06a9\\u0647 \\u0628\\u0627\\u06cc\\u062f \\u0628\\u0627 \\u062a\\u0648\\u062c\\u0647 \\u0628\\u0647 \\u062f\\u0627\\u062f \\u0647\\u0627\\u06cc \\u0645\\u0648\\u062c\\u0648\\u062f \\u0628\\u0627\\u06cc\\u062f \\u06cc\\u0627\\u062f \\u0628\\u06af\\u06cc\\u0631\\u0647\\n\\n\\nlin_reg=LinearRegression()\\n# \\u0628\\u0647\\u0634 \\u0645\\u06cc\\u06af\\u06cc\\u0645 \\u06cc\\u0627\\u062f\\u0628\\u06af\\u06cc\\u0631\\u0647 ...\\nlin_reg.fit(housing_prepared_df,df_label)\\n\\n\\n\\nsample_data_prepared=housing_prepared_df.iloc[:4]\\n# print(\\\"predictions:\\\\t\\\",lin_reg.predict(sample_data_prepared))\\n\\nprint(\\\"predictions:\\\\t\\\",list(map('{:.1f}'.format,lin_reg.predict(sample_data_prepared))))\\n\\n\\nsample_labels=df_label.iloc[:4]\\nprint(\\\"labbels:\\\\t\\\",list(sample_labels))\\n# \\u062e\\u0628 \\u062d\\u0627\\u0644\\u0627 \\u0628\\u0627\\u06cc\\u062f \\u0628\\u0628\\u06cc\\u0646\\u06cc\\u0645 \\u0627\\u06cc\\u0646 \\u067e\\u06cc\\u0634\\u0628\\u06cc\\u0646\\u06cc \\u062e\\u0648\\u0628\\u0647 \\u06cc\\u0627 \\u0646\\u0647\\n# \\u0646\\u06cc\\u0627\\u0632 \\u0628\\u0647 \\u06cc\\u06a9 \\u0645\\u0639\\u06cc\\u0627\\u0631 \\u062f\\u0627\\u0631\\u06cc\\u0645\\n# \\u06cc\\u06a9\\u06cc \\u0627\\u0632 \\u0627\\u06cc\\u0646 \\u0645\\u0639\\u06cc\\u0627\\u0631 \\u0647\\u0627 \\n# RMSE -> root mean squared error\\n# \\u0627\\u0633\\u062a\\n# \\u062a\\u0648\\u0627\\u0646 \\u062f\\u0648\\u0645 \\u0627\\u062e\\u062a\\u0644\\u0627\\u0641 \\u0631\\u0648 \\u0628\\u062f\\u0633\\u062a \\u0645\\u06cc\\u0627\\u0631\\u0647 \\u0648 \\u0645\\u06cc\\u0628\\u0631\\u0647 \\u0632\\u0632\\u06cc\\u0631 \\u0631\\u0627\\u062f\\u06cc\\u06a9\\u0627\\u0644\";\n",
       "                var nbb_formatted_code = \"# step 5 :\\n# \\u062f\\u0631 \\u0627\\u06cc\\u0646 \\u0645\\u0631\\u062d\\u0644\\u0647 \\u0628\\u0627\\u06cc\\u062f \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\u0647\\u0627\\u06cc \\u0631\\u06af\\u0631\\u0633\\u06cc\\u0648\\u0646 \\u0645\\u062e\\u062a\\u0644\\u0641 \\u0631\\u0648 \\u062a\\u0633\\u062a \\u06a9\\u0646\\u06cc\\u0645\\n\\n# \\u0627\\u0648\\u0644\\u06cc\\u0646 \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645\\n# \\u0644\\u06cc\\u0646\\u0646\\u06cc\\u0631 \\u0631\\u06af\\u0631\\u0633\\u06cc\\u0648\\u0646\\nfrom sklearn.linear_model import LinearRegression\\n\\n# \\u0627\\u0648\\u0644\\u06cc\\u0646 \\u06a9\\u0627\\u0631\\u06cc \\u06a9\\u0647 \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\u0645\\u0627 \\u0628\\u0627\\u06cc\\u062f \\u0628\\u06a9\\u0646\\u0647 \\u0627\\u06cc\\u0646\\u0647 \\u06a9\\u0647 \\u0628\\u0627\\u06cc\\u062f \\u0628\\u0627 \\u062a\\u0648\\u062c\\u0647 \\u0628\\u0647 \\u062f\\u0627\\u062f \\u0647\\u0627\\u06cc \\u0645\\u0648\\u062c\\u0648\\u062f \\u0628\\u0627\\u06cc\\u062f \\u06cc\\u0627\\u062f \\u0628\\u06af\\u06cc\\u0631\\u0647\\n\\n\\nlin_reg = LinearRegression()\\n# \\u0628\\u0647\\u0634 \\u0645\\u06cc\\u06af\\u06cc\\u0645 \\u06cc\\u0627\\u062f\\u0628\\u06af\\u06cc\\u0631\\u0647 ...\\nlin_reg.fit(housing_prepared_df, df_label)\\n\\n\\nsample_data_prepared = housing_prepared_df.iloc[:4]\\n# print(\\\"predictions:\\\\t\\\",lin_reg.predict(sample_data_prepared))\\n\\nprint(\\n    \\\"predictions:\\\\t\\\", list(map(\\\"{:.1f}\\\".format, lin_reg.predict(sample_data_prepared)))\\n)\\n\\n\\nsample_labels = df_label.iloc[:4]\\nprint(\\\"labbels:\\\\t\\\", list(sample_labels))\\n# \\u062e\\u0628 \\u062d\\u0627\\u0644\\u0627 \\u0628\\u0627\\u06cc\\u062f \\u0628\\u0628\\u06cc\\u0646\\u06cc\\u0645 \\u0627\\u06cc\\u0646 \\u067e\\u06cc\\u0634\\u0628\\u06cc\\u0646\\u06cc \\u062e\\u0648\\u0628\\u0647 \\u06cc\\u0627 \\u0646\\u0647\\n# \\u0646\\u06cc\\u0627\\u0632 \\u0628\\u0647 \\u06cc\\u06a9 \\u0645\\u0639\\u06cc\\u0627\\u0631 \\u062f\\u0627\\u0631\\u06cc\\u0645\\n# \\u06cc\\u06a9\\u06cc \\u0627\\u0632 \\u0627\\u06cc\\u0646 \\u0645\\u0639\\u06cc\\u0627\\u0631 \\u0647\\u0627\\n# RMSE -> root mean squared error\\n# \\u0627\\u0633\\u062a\\n# \\u062a\\u0648\\u0627\\u0646 \\u062f\\u0648\\u0645 \\u0627\\u062e\\u062a\\u0644\\u0627\\u0641 \\u0631\\u0648 \\u0628\\u062f\\u0633\\u062a \\u0645\\u06cc\\u0627\\u0631\\u0647 \\u0648 \\u0645\\u06cc\\u0628\\u0631\\u0647 \\u0632\\u0632\\u06cc\\u0631 \\u0631\\u0627\\u062f\\u06cc\\u06a9\\u0627\\u0644\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# step 5 :\n",
    "# در این مرحله باید الگوریتم های رگرسیون مختلف رو تست کنیم\n",
    "\n",
    "# اولین الگوریتم \n",
    "# لیننیر رگرسیون\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# اولین کاری که الگوریتم ما باید بکنه اینه که باید با توجه به داد های موجود باید یاد بگیره\n",
    "\n",
    "\n",
    "lin_reg=LinearRegression()\n",
    "# بهش میگیم یادبگیره ...\n",
    "lin_reg.fit(housing_prepared_df,df_label)\n",
    "\n",
    "\n",
    "\n",
    "sample_data_prepared=housing_prepared_df.iloc[:4]\n",
    "# print(\"predictions:\\t\",lin_reg.predict(sample_data_prepared))\n",
    "\n",
    "print(\"predictions:\\t\",list(map('{:.1f}'.format,lin_reg.predict(sample_data_prepared))))\n",
    "\n",
    "\n",
    "sample_labels=df_label.iloc[:4]\n",
    "print(\"labbels:\\t\",list(sample_labels))\n",
    "# خب حالا باید ببینیم این پیشبینی خوبه یا نه\n",
    "# نیاز به یک معیار داریم\n",
    "# یکی از این معیار ها \n",
    "# RMSE -> root mean squared error\n",
    "# است\n",
    "# توان دوم اختلاف رو بدست میاره و میبره ززیر رادیکال\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "812dbd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68002.59920052272"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# \\u0645\\u0639\\u06cc\\u0627\\u0631 \\u0627\\u06cc\\u0646\\u06a9\\u0647 \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\u0686\\u0637\\u0648\\u0631\\u0647....\\n\\nfrom sklearn.metrics import mean_squared_error\\n# RMSE -> root mean squared error\\n# \\u0645\\u06cc \\u06af\\u06cc\\u0645 \\u0628\\u0631\\u0627\\u06cc \\u062a\\u0645\\u0627\\u0645 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627 \\u067e\\u06cc\\u0634\\u0628\\u06cc\\u0646\\u06cc \\u0627\\u0646\\u062c\\u0627\\u0645 \\u0628\\u062f\\u0647\\n# \\u0648 \\u062d\\u0627\\u0635\\u0644 \\u0631\\u0627 \\u062f\\u0631 \\u0647\\u0648\\u0633\\u06cc\\u0646\\u06af \\u067e\\u0631\\u062f\\u06cc\\u06a9\\u0634\\u0646 \\u0628\\u0631\\u06cc\\u0632\\n\\nhousing_predictions=lin_reg.predict(housing_prepared_df)\\n# \\u062d\\u0627\\u0644 \\u0645\\u06cc \\u06af\\u0648\\u06cc\\u0645\\u0645 \\u0645\\u06cc\\u0646 \\u0627\\u0633\\u06a9\\u0648\\u06cc\\u0631 \\u0631\\u0648 \\u0635\\u062f\\u0627 \\u0628\\u0632\\u0646 \\u0648 \\u0627\\u06cc\\u0646 \\u062f\\u0648\\u062a\\u0627 \\u0631\\u0648 \\u0645\\u0642\\u0627\\u06cc\\u0633\\u0647 \\u06a9\\u0646 \\u0641\\u0631\\u0642 \\u0646\\u062f\\u0627\\u0631\\u0647 \\u06a9\\u062f\\u0648\\u0645\\u0627\\u0648\\u0644 \\u0628\\u0627\\u0634\\u0647\\n\\nlin_mse=mean_squared_error(df_label,housing_predictions)\\n#  \\nlin_rmse=np.sqrt(lin_mse)\\n# \\u0645\\u06cc\\u0627\\u0646\\u06af\\u06cc\\u0646 \\u067e\\u06cc\\u0634 \\u0628\\u06cc\\u0646\\u06cc \\nlin_rmse\";\n",
       "                var nbb_formatted_code = \"# \\u0645\\u0639\\u06cc\\u0627\\u0631 \\u0627\\u06cc\\u0646\\u06a9\\u0647 \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\u0686\\u0637\\u0648\\u0631\\u0647....\\n\\nfrom sklearn.metrics import mean_squared_error\\n\\n# RMSE -> root mean squared error\\n# \\u0645\\u06cc \\u06af\\u06cc\\u0645 \\u0628\\u0631\\u0627\\u06cc \\u062a\\u0645\\u0627\\u0645 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627 \\u067e\\u06cc\\u0634\\u0628\\u06cc\\u0646\\u06cc \\u0627\\u0646\\u062c\\u0627\\u0645 \\u0628\\u062f\\u0647\\n# \\u0648 \\u062d\\u0627\\u0635\\u0644 \\u0631\\u0627 \\u062f\\u0631 \\u0647\\u0648\\u0633\\u06cc\\u0646\\u06af \\u067e\\u0631\\u062f\\u06cc\\u06a9\\u0634\\u0646 \\u0628\\u0631\\u06cc\\u0632\\n\\nhousing_predictions = lin_reg.predict(housing_prepared_df)\\n# \\u062d\\u0627\\u0644 \\u0645\\u06cc \\u06af\\u0648\\u06cc\\u0645\\u0645 \\u0645\\u06cc\\u0646 \\u0627\\u0633\\u06a9\\u0648\\u06cc\\u0631 \\u0631\\u0648 \\u0635\\u062f\\u0627 \\u0628\\u0632\\u0646 \\u0648 \\u0627\\u06cc\\u0646 \\u062f\\u0648\\u062a\\u0627 \\u0631\\u0648 \\u0645\\u0642\\u0627\\u06cc\\u0633\\u0647 \\u06a9\\u0646 \\u0641\\u0631\\u0642 \\u0646\\u062f\\u0627\\u0631\\u0647 \\u06a9\\u062f\\u0648\\u0645\\u0627\\u0648\\u0644 \\u0628\\u0627\\u0634\\u0647\\n\\nlin_mse = mean_squared_error(df_label, housing_predictions)\\n#\\nlin_rmse = np.sqrt(lin_mse)\\n# \\u0645\\u06cc\\u0627\\u0646\\u06af\\u06cc\\u0646 \\u067e\\u06cc\\u0634 \\u0628\\u06cc\\u0646\\u06cc\\nlin_rmse\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# معیار اینکه الگوریتم چطوره....\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# RMSE -> root mean squared error\n",
    "# می گیم برای تمام داده ها پیشبینی انجام بده\n",
    "# و حاصل را در هوسینگ پردیکشن بریز\n",
    "\n",
    "housing_predictions=lin_reg.predict(housing_prepared_df)\n",
    "# حال می گویمم مین اسکویر رو صدا بزن و این دوتا رو مقایسه کن فرق نداره کدوماول باشه\n",
    "\n",
    "lin_mse=mean_squared_error(df_label,housing_predictions)\n",
    "#  \n",
    "lin_rmse=np.sqrt(lin_mse)\n",
    "# میانگین پیش بینی \n",
    "lin_rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e948789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\u062f\\u0648\\u0645 \\u0631\\u06af\\u0631\\u06cc\\u0633\\u0648\\u0646\\nfrom sklearn.tree import DecisionTreeRegressor\\n\\n\\ntree_reg = DecisionTreeRegressor()\\n# \\u06cc\\u0627\\u062f\\u0628\\u06af\\u06cc\\u0631\\u06cc \\n\\ntree_reg.fit(housing_prepared_df, df_label)\\n\\n# \\u067e\\u06cc\\u0634 \\u0628\\u06cc\\u0646\\u06cc \\u06a9\\u0646\\nhousing_predictionss = tree_reg.predict(housing_prepared_df)\\n\\n# \\u0645\\u0639\\u06cc\\u0627\\u0631\\ntree_mse = mean_squared_error(df_label, housing_predictionss)\\ntree_rmse = np.sqrt(tree_mse)\\n\\n\\ntree_rmse\\n\\n# \\u0648\\u0642\\u062a\\u06cc \\u0645\\u062b\\u0644 \\u0627\\u0644\\u0627\\u0646 \\u0635\\u0641\\u0631 \\u0628\\u0647 \\u0639\\u0646\\u0648\\u0627\\u0646 \\u062e\\u0631\\u0648\\u062c\\u06cc \\u062f\\u0627\\u062f \\u06cc\\u0639\\u0646\\u06cc \\u06cc\\u0647\\u062c\\u0627\\u06cc \\u06a9\\u0627\\u0631 \\u0645\\u06cc\\u0644\\u0646\\u06af\\u0647\\n# \\u062f\\u0644\\u06cc\\u0644\\u0634 \\u0627\\u06cc\\u0646\\u0647 \\u0628\\u0627 \\u0647\\u0645\\u0648\\u0646 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627\\u06cc \\u06a9\\u0647 \\u0627\\u0645\\u0648\\u0632\\u0634 \\u062f\\u0627\\u062f\\u06cc\\u0645\\n# \\u062f\\u0627\\u0631\\u06cc\\u0645 \\u062a\\u0633\\u062a \\u0645\\u06cc\\u06a9\\u0646\\u06cc\\u0645\";\n",
       "                var nbb_formatted_code = \"# \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\u062f\\u0648\\u0645 \\u0631\\u06af\\u0631\\u06cc\\u0633\\u0648\\u0646\\nfrom sklearn.tree import DecisionTreeRegressor\\n\\n\\ntree_reg = DecisionTreeRegressor()\\n# \\u06cc\\u0627\\u062f\\u0628\\u06af\\u06cc\\u0631\\u06cc\\n\\ntree_reg.fit(housing_prepared_df, df_label)\\n\\n# \\u067e\\u06cc\\u0634 \\u0628\\u06cc\\u0646\\u06cc \\u06a9\\u0646\\nhousing_predictionss = tree_reg.predict(housing_prepared_df)\\n\\n# \\u0645\\u0639\\u06cc\\u0627\\u0631\\ntree_mse = mean_squared_error(df_label, housing_predictionss)\\ntree_rmse = np.sqrt(tree_mse)\\n\\n\\ntree_rmse\\n\\n# \\u0648\\u0642\\u062a\\u06cc \\u0645\\u062b\\u0644 \\u0627\\u0644\\u0627\\u0646 \\u0635\\u0641\\u0631 \\u0628\\u0647 \\u0639\\u0646\\u0648\\u0627\\u0646 \\u062e\\u0631\\u0648\\u062c\\u06cc \\u062f\\u0627\\u062f \\u06cc\\u0639\\u0646\\u06cc \\u06cc\\u0647\\u062c\\u0627\\u06cc \\u06a9\\u0627\\u0631 \\u0645\\u06cc\\u0644\\u0646\\u06af\\u0647\\n# \\u062f\\u0644\\u06cc\\u0644\\u0634 \\u0627\\u06cc\\u0646\\u0647 \\u0628\\u0627 \\u0647\\u0645\\u0648\\u0646 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627\\u06cc \\u06a9\\u0647 \\u0627\\u0645\\u0648\\u0632\\u0634 \\u062f\\u0627\\u062f\\u06cc\\u0645\\n# \\u062f\\u0627\\u0631\\u06cc\\u0645 \\u062a\\u0633\\u062a \\u0645\\u06cc\\u06a9\\u0646\\u06cc\\u0645\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# الگوریتم دوم رگریسون\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "# یادبگیری \n",
    "\n",
    "tree_reg.fit(housing_prepared_df, df_label)\n",
    "\n",
    "# پیش بینی کن\n",
    "housing_predictionss = tree_reg.predict(housing_prepared_df)\n",
    "\n",
    "# معیار\n",
    "tree_mse = mean_squared_error(df_label, housing_predictionss)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "\n",
    "\n",
    "tree_rmse\n",
    "\n",
    "# وقتی مثل الان صفر به عنوان خروجی داد یعنی یهجای کار میلنگه\n",
    "# دلیلش اینه با همون داده های که اموزش دادیم\n",
    "# داریم تست میکنیم\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09e7fbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Decision Tree Regressor ==========\n",
      "Scores: [66813.09735829 69237.27942135 67617.94553766 70906.03266295\n",
      " 68171.64154464 70148.72080413 71432.09130438 75477.90485099\n",
      " 71740.58477155 74766.77175222]\n",
      "Mean: 70631.20700081579\n",
      "Standard devation: 2728.0768842189295\n",
      "==================================\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# \\u062e\\u0628 \\u0645\\u0627 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627 \\u0631\\u0648 \\u0628\\u0634\\u06a9\\u0646\\u06cc\\u0645 \\n# \\u0628\\u0627 \\u06cc\\u06a9 \\u0642\\u0633\\u0645\\u062a \\u0622\\u0645\\u0648\\u0632\\u0634 \\u0628\\u062f\\u06cc\\u0645 \\u0648 \\u0628\\u0627 \\u06cc\\u06a9 \\u0642\\u0633\\u0645\\u062a \\u062f\\u06cc\\u06af\\u0647 \\u062a\\u0633\\u062a \\u06a9\\u0646\\u06cc\\u0645\\n# \\u0647\\u0645 \\u062f\\u0633\\u062a\\u06cc \\u0645\\u06cc\\u062a\\u0648\\u0646\\u06cc \\u0648 \\u0647\\u0645 \\u0628\\u0627 \\u06a9\\u062a\\u0627\\u0628\\u062e\\u0648\\u0646\\u0647\\nfrom sklearn.model_selection import cross_val_score\\n\\n# cv -> \\u0627\\u06cc\\u0646 \\u0645\\u06cc\\u06af\\u0647 \\u0639\\u0644\\u0627\\u0648\\u0647 \\u0628\\u0631 \\u0627\\u06cc\\u0646\\u06a9\\u0647 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627 \\u0631\\u0648 \\u0628\\u0647 \\u062f\\u0648 \\u0642\\u0633\\u0645\\u062a \\u062a\\u0642\\u0633\\u06cc\\u0645 \\u0645\\u06cc\\u06a9\\u0646\\u0645 \\n# \\u0628\\u0627 \\u06cc\\u06a9 \\u0642\\u0633\\u0645\\u062a \\u06cc\\u0627\\u062f\\u0645\\u06cc\\u06af\\u0631\\u06cc\\u0645 \\u0648 \\u0628\\u0627 \\u06cc\\u06a9 \\u0642\\u0633\\u0645\\u062a \\u062f\\u06cc\\u06af\\u0647 \\u067e\\u06cc\\u0634 \\u0628\\u06cc\\u0646\\u06cc \\n# \\u0645\\u06cc \\u06a9\\u0646\\u06cc\\u0645 \\u0645\\u06cc\\u06af\\u0647 \\u0627\\u06cc\\u0646 \\u06a9\\u0627\\u0631 \\u0631\\u0627 \\u062f\\u0647 \\u0628\\u0627\\u0631 \\u0627\\u0646\\u062c\\u062c\\u0627\\u0645 \\u0645\\u06cc\\u062f\\u0645 \\u0647\\u0631 \\u0628\\u0627\\u0631 \\u0628\\u0627 \\u06cc\\u06a9 \\u0633\\u0631\\u06cc \\u062f\\u06cc\\u062a\\u0627\\u06cc \\u062c\\u062f\\u06cc\\u062f\\n\\nscores=cross_val_score(tree_reg,housing_prepared_df,df_label,scoring='neg_mean_squared_error',cv=10)\\n# \\u0645\\u062a\\u063a\\u06cc\\u06cc\\u0631 \\u067e\\u0627\\u06cc\\u06cc\\u0646 \\u06cc\\u06a9 \\u0627\\u0631\\u0627\\u06cc\\u0647 \\u06f1\\u06f0 \\u062a\\u0627\\u06cc\\u06cc \\u0647\\u0633\\u062a \\u06a9\\u0647 \\n# \\u0647\\u0631 \\u06a9\\u062f\\u0648\\u0645\\u0634 \\u0647\\u0645\\u0648\\u0646 \\u062a\\u0631\\u06cc \\u0627\\u0631 \\u0627\\u0645 \\u0627\\u0633 \\u0627\\u0633 \\u0647\\u0633\\u062a\\u0646  \\u0686\\u0648\\u0646 \\u062f\\u0647 \\u0628\\u0627\\u0631 \\u0627\\u0648\\u0645\\u062f\\u0647 \\u062f\\u0627\\u062f\\u0647 \\u0631\\u0648 \\u0631\\u0646\\u062f\\u0648\\u0645 \\u0686\\u06cc\\u0632 \\u06a9\\u0631\\u062f\\u0647 \\u0648 \\n# \\u067e\\u06cc\\u0634 \\u0628\\u06cc\\u0646\\u06cc \\u06a9\\u0631\\u062f\\u0647\\ntrees_rmse_scores=np.sqrt(-scores)\\n\\n\\ndef display_scores(scores,model_name):\\n    print(\\\"=========\\\",model_name,\\\"==========\\\")\\n    print(\\\"Scores:\\\",scores)\\n    print(\\\"Mean:\\\",scores.mean())\\n    print(\\\"Standard devation:\\\",scores.std())\\n    print(\\\"==================================\\\")\\n    \\n    \\ndisplay_scores(trees_rmse_scores,\\\"Decision Tree Regressor\\\")\\n    \\n\\n# \\u062f\\u0648 \\u0627\\u0635\\u0637\\u0644\\u0627\\u062d \\u062f\\u0627\\u0631\\u06cc\\u0645 \\u0627\\u06cc\\u0646\\u062c\\u0627\\n# over fiting\\n\\n# \\u06cc\\u0639\\u0646\\u06cc \\u062e\\u06cc\\u0644\\u06cc \\u0648\\u0627\\u0628\\u0633\\u062a\\u0647 \\u0627\\u0633\\u062a \\u0628\\u0647 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627\\u06cc\\u06cc \\u06a9\\u0647 \\u0628\\u0627\\u0647\\u0627\\u0634 \\u0627\\u0648\\u0645\\u0632\\u0634 \\u0645\\u06cc\\u0628\\u06cc\\u0646\\u0647\\n# \\u062f\\u06cc\\u062f\\u06cc\\u0645 \\u06a9\\u0647 \\u0627\\u0648\\u0646\\u0645\\u0648\\u0642\\u0639 \\u06a9\\u0647 \\u0628\\u0627 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627\\u06cc\\u06cc \\u06a9\\u0647 \\u0627\\u0645\\u0648\\u0632\\u0634\\u0634 \\u062f\\u0627\\u062f\\u06cc\\u0645 \\n# \\u062a\\u0633\\u062a\\u0633\\u0634 \\u06a9\\u0631\\u062f\\u06cc\\u0645 \\n# \\u062c\\u0648\\u0627\\u0628 \\u0635\\u0641\\u0631 \\u0628\\u0647 \\u0645\\u0627 \\u062f\\u0627\\u062f\\n# \\u0648\\u0644\\u06cc \\u0648\\u0642\\u062a\\u06cc \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627 \\u0631\\u0648 \\u062f\\u0648 \\u0642\\u0633\\u0645\\u062a \\u06a9\\u0631\\u062f\\u06cc\\u0645 \\u0627\\u0635\\u0644\\u0627 \\u062f\\u0627\\u062f \\u0647\\u0627\\u06cc \\u062e\\u0648\\u0628\\u06cc \\u0628\\u0647 \\u0645\\u0627 \\u0646\\u062f\\u0627\\u062f\\n\\n# \\u062f\\u0631 \\u06a9\\u0644 \\u06cc\\u0639\\u0646\\u06cc \\u062e\\u0648\\u0628 \\u0627\\u0645\\u0648\\u0632\\u0634 \\u0646\\u062f\\u06cc\\u062f\\u0647 \\u0648 \\u062e\\u06cc\\u0644\\u06cc \\u062e\\u0648\\u0628 \\u067e\\u06cc\\u0634\\u0628\\u06cc\\u0646\\u06cc \\u0646\\u0645\\u06cc\\u06a9\\u0646\\u0647 \\n\\n\\n# under fit\\n# \\u062f\\u0631\\u06a9\\u0644 \\u062c\\u0648\\u0627\\u0628 \\u062e\\u0648\\u0628\\u06cc \\u0628\\u0647 \\u0645\\u0627 \\u0646\\u0645\\u06cc\\u062f\\u0647\\n# \\u0645\\u062b\\u0644\\u0627 \\u0644\\u06cc\\u0646\\u0646\\u06cc\\u0631 \\u0631\\u06af\\u0631\\u0633\\u06cc\\u0648\\u0646 \\n# \\u062f\\u0631 \\u06a9\\u0644 \\u062c\\u0648\\u0627\\u0628 \\u062e\\u0648\\u0628\\u06cc \\u0628\\u0647 \\u0645\\u0627 \\u0646\\u0645\\u06cc\\u062f\\u0647 \";\n",
       "                var nbb_formatted_code = \"# \\u062e\\u0628 \\u0645\\u0627 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627 \\u0631\\u0648 \\u0628\\u0634\\u06a9\\u0646\\u06cc\\u0645\\n# \\u0628\\u0627 \\u06cc\\u06a9 \\u0642\\u0633\\u0645\\u062a \\u0622\\u0645\\u0648\\u0632\\u0634 \\u0628\\u062f\\u06cc\\u0645 \\u0648 \\u0628\\u0627 \\u06cc\\u06a9 \\u0642\\u0633\\u0645\\u062a \\u062f\\u06cc\\u06af\\u0647 \\u062a\\u0633\\u062a \\u06a9\\u0646\\u06cc\\u0645\\n# \\u0647\\u0645 \\u062f\\u0633\\u062a\\u06cc \\u0645\\u06cc\\u062a\\u0648\\u0646\\u06cc \\u0648 \\u0647\\u0645 \\u0628\\u0627 \\u06a9\\u062a\\u0627\\u0628\\u062e\\u0648\\u0646\\u0647\\nfrom sklearn.model_selection import cross_val_score\\n\\n# cv -> \\u0627\\u06cc\\u0646 \\u0645\\u06cc\\u06af\\u0647 \\u0639\\u0644\\u0627\\u0648\\u0647 \\u0628\\u0631 \\u0627\\u06cc\\u0646\\u06a9\\u0647 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627 \\u0631\\u0648 \\u0628\\u0647 \\u062f\\u0648 \\u0642\\u0633\\u0645\\u062a \\u062a\\u0642\\u0633\\u06cc\\u0645 \\u0645\\u06cc\\u06a9\\u0646\\u0645\\n# \\u0628\\u0627 \\u06cc\\u06a9 \\u0642\\u0633\\u0645\\u062a \\u06cc\\u0627\\u062f\\u0645\\u06cc\\u06af\\u0631\\u06cc\\u0645 \\u0648 \\u0628\\u0627 \\u06cc\\u06a9 \\u0642\\u0633\\u0645\\u062a \\u062f\\u06cc\\u06af\\u0647 \\u067e\\u06cc\\u0634 \\u0628\\u06cc\\u0646\\u06cc\\n# \\u0645\\u06cc \\u06a9\\u0646\\u06cc\\u0645 \\u0645\\u06cc\\u06af\\u0647 \\u0627\\u06cc\\u0646 \\u06a9\\u0627\\u0631 \\u0631\\u0627 \\u062f\\u0647 \\u0628\\u0627\\u0631 \\u0627\\u0646\\u062c\\u062c\\u0627\\u0645 \\u0645\\u06cc\\u062f\\u0645 \\u0647\\u0631 \\u0628\\u0627\\u0631 \\u0628\\u0627 \\u06cc\\u06a9 \\u0633\\u0631\\u06cc \\u062f\\u06cc\\u062a\\u0627\\u06cc \\u062c\\u062f\\u06cc\\u062f\\n\\nscores = cross_val_score(\\n    tree_reg, housing_prepared_df, df_label, scoring=\\\"neg_mean_squared_error\\\", cv=10\\n)\\n# \\u0645\\u062a\\u063a\\u06cc\\u06cc\\u0631 \\u067e\\u0627\\u06cc\\u06cc\\u0646 \\u06cc\\u06a9 \\u0627\\u0631\\u0627\\u06cc\\u0647 \\u06f1\\u06f0 \\u062a\\u0627\\u06cc\\u06cc \\u0647\\u0633\\u062a \\u06a9\\u0647\\n# \\u0647\\u0631 \\u06a9\\u062f\\u0648\\u0645\\u0634 \\u0647\\u0645\\u0648\\u0646 \\u062a\\u0631\\u06cc \\u0627\\u0631 \\u0627\\u0645 \\u0627\\u0633 \\u0627\\u0633 \\u0647\\u0633\\u062a\\u0646  \\u0686\\u0648\\u0646 \\u062f\\u0647 \\u0628\\u0627\\u0631 \\u0627\\u0648\\u0645\\u062f\\u0647 \\u062f\\u0627\\u062f\\u0647 \\u0631\\u0648 \\u0631\\u0646\\u062f\\u0648\\u0645 \\u0686\\u06cc\\u0632 \\u06a9\\u0631\\u062f\\u0647 \\u0648\\n# \\u067e\\u06cc\\u0634 \\u0628\\u06cc\\u0646\\u06cc \\u06a9\\u0631\\u062f\\u0647\\ntrees_rmse_scores = np.sqrt(-scores)\\n\\n\\ndef display_scores(scores, model_name):\\n    print(\\\"=========\\\", model_name, \\\"==========\\\")\\n    print(\\\"Scores:\\\", scores)\\n    print(\\\"Mean:\\\", scores.mean())\\n    print(\\\"Standard devation:\\\", scores.std())\\n    print(\\\"==================================\\\")\\n\\n\\ndisplay_scores(trees_rmse_scores, \\\"Decision Tree Regressor\\\")\\n\\n\\n# \\u062f\\u0648 \\u0627\\u0635\\u0637\\u0644\\u0627\\u062d \\u062f\\u0627\\u0631\\u06cc\\u0645 \\u0627\\u06cc\\u0646\\u062c\\u0627\\n# over fiting\\n\\n# \\u06cc\\u0639\\u0646\\u06cc \\u062e\\u06cc\\u0644\\u06cc \\u0648\\u0627\\u0628\\u0633\\u062a\\u0647 \\u0627\\u0633\\u062a \\u0628\\u0647 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627\\u06cc\\u06cc \\u06a9\\u0647 \\u0628\\u0627\\u0647\\u0627\\u0634 \\u0627\\u0648\\u0645\\u0632\\u0634 \\u0645\\u06cc\\u0628\\u06cc\\u0646\\u0647\\n# \\u062f\\u06cc\\u062f\\u06cc\\u0645 \\u06a9\\u0647 \\u0627\\u0648\\u0646\\u0645\\u0648\\u0642\\u0639 \\u06a9\\u0647 \\u0628\\u0627 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627\\u06cc\\u06cc \\u06a9\\u0647 \\u0627\\u0645\\u0648\\u0632\\u0634\\u0634 \\u062f\\u0627\\u062f\\u06cc\\u0645\\n# \\u062a\\u0633\\u062a\\u0633\\u0634 \\u06a9\\u0631\\u062f\\u06cc\\u0645\\n# \\u062c\\u0648\\u0627\\u0628 \\u0635\\u0641\\u0631 \\u0628\\u0647 \\u0645\\u0627 \\u062f\\u0627\\u062f\\n# \\u0648\\u0644\\u06cc \\u0648\\u0642\\u062a\\u06cc \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627 \\u0631\\u0648 \\u062f\\u0648 \\u0642\\u0633\\u0645\\u062a \\u06a9\\u0631\\u062f\\u06cc\\u0645 \\u0627\\u0635\\u0644\\u0627 \\u062f\\u0627\\u062f \\u0647\\u0627\\u06cc \\u062e\\u0648\\u0628\\u06cc \\u0628\\u0647 \\u0645\\u0627 \\u0646\\u062f\\u0627\\u062f\\n\\n# \\u062f\\u0631 \\u06a9\\u0644 \\u06cc\\u0639\\u0646\\u06cc \\u062e\\u0648\\u0628 \\u0627\\u0645\\u0648\\u0632\\u0634 \\u0646\\u062f\\u06cc\\u062f\\u0647 \\u0648 \\u062e\\u06cc\\u0644\\u06cc \\u062e\\u0648\\u0628 \\u067e\\u06cc\\u0634\\u0628\\u06cc\\u0646\\u06cc \\u0646\\u0645\\u06cc\\u06a9\\u0646\\u0647\\n\\n\\n# under fit\\n# \\u062f\\u0631\\u06a9\\u0644 \\u062c\\u0648\\u0627\\u0628 \\u062e\\u0648\\u0628\\u06cc \\u0628\\u0647 \\u0645\\u0627 \\u0646\\u0645\\u06cc\\u062f\\u0647\\n# \\u0645\\u062b\\u0644\\u0627 \\u0644\\u06cc\\u0646\\u0646\\u06cc\\u0631 \\u0631\\u06af\\u0631\\u0633\\u06cc\\u0648\\u0646\\n# \\u062f\\u0631 \\u06a9\\u0644 \\u062c\\u0648\\u0627\\u0628 \\u062e\\u0648\\u0628\\u06cc \\u0628\\u0647 \\u0645\\u0627 \\u0646\\u0645\\u06cc\\u062f\\u0647\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# خب ما داده ها رو بشکنیم \n",
    "# با یک قسمت آموزش بدیم و با یک قسمت دیگه تست کنیم\n",
    "# هم دستی میتونی و هم با کتابخونه\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# cv -> این میگه علاوه بر اینکه داده ها رو به دو قسمت تقسیم میکنم \n",
    "# با یک قسمت یادمیگریم و با یک قسمت دیگه پیش بینی \n",
    "# می کنیم میگه این کار را ده بار انججام میدم هر بار با یک سری دیتای جدید\n",
    "\n",
    "scores=cross_val_score(tree_reg,housing_prepared_df,df_label,scoring='neg_mean_squared_error',cv=10)\n",
    "# متغییر پایین یک ارایه ۱۰ تایی هست که \n",
    "# هر کدومش همون تری ار ام اس اس هستن  چون ده بار اومده داده رو رندوم چیز کرده و \n",
    "# پیش بینی کرده\n",
    "trees_rmse_scores=np.sqrt(-scores)\n",
    "\n",
    "\n",
    "def display_scores(scores,model_name):\n",
    "    print(\"=========\",model_name,\"==========\")\n",
    "    print(\"Scores:\",scores)\n",
    "    print(\"Mean:\",scores.mean())\n",
    "    print(\"Standard devation:\",scores.std())\n",
    "    print(\"==================================\")\n",
    "    \n",
    "    \n",
    "display_scores(trees_rmse_scores,\"Decision Tree Regressor\")\n",
    "    \n",
    "\n",
    "# دو اصطلاح داریم اینجا\n",
    "# over fiting\n",
    "\n",
    "# یعنی خیلی وابسته است به داده هایی که باهاش اومزش میبینه\n",
    "# دیدیم که اونموقع که با داده هایی که اموزشش دادیم \n",
    "# تستسش کردیم \n",
    "# جواب صفر به ما داد\n",
    "# ولی وقتی داده ها رو دو قسمت کردیم اصلا داد های خوبی به ما نداد\n",
    "\n",
    "# در کل یعنی خوب اموزش ندیده و خیلی خوب پیشبینی نمیکنه \n",
    "\n",
    "\n",
    "# under fit\n",
    "# درکل جواب خوبی به ما نمیده\n",
    "# مثلا لیننیر رگرسیون \n",
    "# در کل جواب خوبی به ما نمیده \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45f843a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Linear Regression ==========\n",
      "Scores: [69950.61650899 63993.05359694 66324.31912505 70399.13260056\n",
      " 71963.38185731 68108.91634653 66321.73105565 66916.82419747\n",
      " 68098.47371781 70485.9307219 ]\n",
      "Mean: 68256.23797282019\n",
      "Standard devation: 2316.621516305121\n",
      "==================================\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"# \\u0642\\u0628\\u0644 \\u0627\\u0632 \\u0627\\u06cc\\u0646\\u06a9\\u0647 \\u06cc\\u06a9 \\u0631\\u0648\\u0634 \\u062f\\u06cc\\u06af\\u0647 \\u0631\\u0648 \\u062a\\u0633\\u062a \\u06a9\\u0646\\u06cc\\u0645 \\n# \\u0628\\u0631\\u0627\\u06cc \\u0631\\u06af\\u0631\\u0633\\u06cc\\u0648\\u0646 \\u062e\\u0637\\u06cc \\u06a9\\u0647 \\u0647\\u0645 \\u0628\\u0627 \\u0647\\u0645\\u0648\\u0646 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627\\u06cc \\u06a9\\u0647 \\u0627\\u0645\\u0648\\u0632\\u0634 \\u062f\\u0627\\u062f\\u06cc\\u0645\\n# \\u062a\\u0633\\u062a \\u06a9\\u0631\\u062f\\u06cc\\u0645 \\u062d\\u0627\\u0644\\u0627 \\u0645\\u06cc\\u0627\\u06cc\\u06cc\\u0645 \\u0627\\u06cc\\u0646 \\u0631\\u0648 \\u062f\\u0631\\u0633\\u062a\\u0634 \\u0645\\u06cc\\u06a9\\u0646\\u06cc\\u0645\\n\\n\\n\\nlinner_scores=cross_val_score(lin_reg,housing_prepared_df,df_label,scoring='neg_mean_squared_error',cv=10)\\nlinner_rmse_score=np.sqrt(-linner_scores)\\n\\n\\ndisplay_scores(linner_rmse_score,\\\"Linear Regression\\\")\";\n",
       "                var nbb_formatted_code = \"# \\u0642\\u0628\\u0644 \\u0627\\u0632 \\u0627\\u06cc\\u0646\\u06a9\\u0647 \\u06cc\\u06a9 \\u0631\\u0648\\u0634 \\u062f\\u06cc\\u06af\\u0647 \\u0631\\u0648 \\u062a\\u0633\\u062a \\u06a9\\u0646\\u06cc\\u0645\\n# \\u0628\\u0631\\u0627\\u06cc \\u0631\\u06af\\u0631\\u0633\\u06cc\\u0648\\u0646 \\u062e\\u0637\\u06cc \\u06a9\\u0647 \\u0647\\u0645 \\u0628\\u0627 \\u0647\\u0645\\u0648\\u0646 \\u062f\\u0627\\u062f\\u0647 \\u0647\\u0627\\u06cc \\u06a9\\u0647 \\u0627\\u0645\\u0648\\u0632\\u0634 \\u062f\\u0627\\u062f\\u06cc\\u0645\\n# \\u062a\\u0633\\u062a \\u06a9\\u0631\\u062f\\u06cc\\u0645 \\u062d\\u0627\\u0644\\u0627 \\u0645\\u06cc\\u0627\\u06cc\\u06cc\\u0645 \\u0627\\u06cc\\u0646 \\u0631\\u0648 \\u062f\\u0631\\u0633\\u062a\\u0634 \\u0645\\u06cc\\u06a9\\u0646\\u06cc\\u0645\\n\\n\\nlinner_scores = cross_val_score(\\n    lin_reg, housing_prepared_df, df_label, scoring=\\\"neg_mean_squared_error\\\", cv=10\\n)\\nlinner_rmse_score = np.sqrt(-linner_scores)\\n\\n\\ndisplay_scores(linner_rmse_score, \\\"Linear Regression\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# قبل از اینکه یک روش دیگه رو تست کنیم \n",
    "# برای رگرسیون خطی که هم با همون داده های که اموزش دادیم\n",
    "# تست کردیم حالا میاییم این رو درستش میکنیم\n",
    "\n",
    "\n",
    "\n",
    "linner_scores=cross_val_score(lin_reg,housing_prepared_df,df_label,scoring='neg_mean_squared_error',cv=10)\n",
    "linner_rmse_score=np.sqrt(-linner_scores)\n",
    "\n",
    "\n",
    "display_scores(linner_rmse_score,\"Linear Regression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbfc6e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Random Forest Regressor ==========\n",
      "Scores: [51243.87269138 47051.93632615 46998.32316024 49604.05302357\n",
      " 49262.15393377 48928.28604297 50161.94987108 51551.46676335\n",
      " 49734.50902062 52935.9578537 ]\n",
      "Mean: 49747.25086868267\n",
      "Standard devation: 1777.1582316332212\n",
      "==================================\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"# \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\u06f3\\n# RandomForesRegressor\\n# \\u0627\\u06cc\\u0646 \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\n# ensemble\\n# \\u0627\\u0633\\u062a \\u06cc\\u0639\\u0646\\u06cc \\u062a\\u0631\\u06a9\\u06cc\\u0628\\u06cc \\u0627\\u0632 \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\u0647\\u0627\\u06cc \\u062f\\u06cc\\u06af\\u0631 \\u0627\\u0633\\u062a\\n# \\u0645\\u0639\\u0645\\u0648\\u0644\\u0627 \\u0627\\u06cc\\u0646 \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\u0647\\u0627 \\u0632\\u0645\\u0627\\u0646 \\u0628\\u0631 \\u0627\\u0633\\u062a \\u0627\\u0645\\u0627 \\u062f\\u0642\\u06cc\\u0642 \\u062a\\u0631 \\u0627\\u0633\\u062a...\\n\\n# =======\\n# \\u062e\\u0628 \\n# RandomForesRegressor\\n# \\u0645\\u06cc\\u0627\\u062f \\u0627\\u0632 \\u0686\\u0646\\u062f\\u06cc\\u0646 \\n# Decision Tree\\n# \\u0627\\u0633\\u062a\\u0641\\u0627\\u062f\\u0647 \\u0645\\u06cc\\u06a9\\u0646\\u0647\\n# \\u0647\\u0631 \\n# Decision Tree \\n# \\u0631\\u0627 \\u0628\\u0627 \\u062a\\u0627\\u06a9\\u062a\\u06cc\\u06a9 \\u0647\\u0627\\u06cc \\u0645\\u062e\\u062a\\u0644\\u0641 \\n# \\u062a\\u0633\\u062a \\u0645\\u06cc\\u06a9\\u0646\\u0647 \\u0648 \\u0647\\u0645\\u0647 \\u0627\\u06cc\\u0646\\u0647\\u0627 \\u0631\\u0648 \\u0628\\u0627\\u0647\\u0645 \\u0645\\u06cc\\u0627\\u0646\\u06af\\u06cc\\u0646 \\u0645\\u06cc\\u06af\\u06cc\\u0631\\u0647 \\u0648 \\u062d\\u0627\\u0635\\u0644 \\u06a9\\u0627\\u0631 \\u0631\\u0627 \\u0628\\u0647 \\u0645\\u0627 \\u0645\\u06cc\\u062f\\u0647\\n\\n# \\u06cc\\u0639\\u0646\\u06cc \\u0645\\u062b\\u0644 \\u0627\\u06cc\\u0646\\u0647 \\u06a9\\u0647 \\u0686\\u0646\\u062f\\u06cc\\u0646 \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\u067e\\u06cc\\u0634 \\u0628\\u06cc\\u0646\\u06cc \\u0631\\u0648 \\u0628\\u0627 \\u0647\\u0645\\n# \\u0627\\u0633\\u062a\\u0641\\u0627\\u062f\\u0647 \\u06a9\\u0646\\u06cc \\u0648 \\u062f\\u0631 \\u0627\\u062e\\u0631 \\u062d\\u0627\\u0635\\u0644 \\u0645\\u06cc\\u0627\\u0646\\u06af\\u06cc\\u0646 \\u0647\\u0645\\u0634\\u0648\\u0646 \\u0631\\u0648 \\u0686\\u06cc\\u0632 \\u06a9\\u0646\\u06cc\\n\\nfrom sklearn.ensemble import RandomForestRegressor\\n\\n\\nforest_reg = RandomForestRegressor()\\n# \\u06cc\\u0627\\u062f\\u0628\\u06af\\u06cc\\u0631\\u06cc \\n\\nforest_reg.fit(housing_prepared_df, df_label)\\n\\n# \\u067e\\u06cc\\u0634 \\u0628\\u06cc\\u0646\\u06cc \\u06a9\\u0646\\nhousing_predictionss = forest_reg.predict(housing_prepared_df)\\n\\n\\n\\nforest_scores=cross_val_score(forest_reg,housing_prepared_df,df_label,scoring='neg_mean_squared_error',cv=10)\\nforest_rmse_score=np.sqrt(-forest_scores)\\n\\n\\n\\ndisplay_scores(forest_rmse_score,\\\"Random Forest Regressor\\\")\";\n",
       "                var nbb_formatted_code = \"# \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\u06f3\\n# RandomForesRegressor\\n# \\u0627\\u06cc\\u0646 \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645\\n# ensemble\\n# \\u0627\\u0633\\u062a \\u06cc\\u0639\\u0646\\u06cc \\u062a\\u0631\\u06a9\\u06cc\\u0628\\u06cc \\u0627\\u0632 \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\u0647\\u0627\\u06cc \\u062f\\u06cc\\u06af\\u0631 \\u0627\\u0633\\u062a\\n# \\u0645\\u0639\\u0645\\u0648\\u0644\\u0627 \\u0627\\u06cc\\u0646 \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\u0647\\u0627 \\u0632\\u0645\\u0627\\u0646 \\u0628\\u0631 \\u0627\\u0633\\u062a \\u0627\\u0645\\u0627 \\u062f\\u0642\\u06cc\\u0642 \\u062a\\u0631 \\u0627\\u0633\\u062a...\\n\\n# =======\\n# \\u062e\\u0628\\n# RandomForesRegressor\\n# \\u0645\\u06cc\\u0627\\u062f \\u0627\\u0632 \\u0686\\u0646\\u062f\\u06cc\\u0646\\n# Decision Tree\\n# \\u0627\\u0633\\u062a\\u0641\\u0627\\u062f\\u0647 \\u0645\\u06cc\\u06a9\\u0646\\u0647\\n# \\u0647\\u0631\\n# Decision Tree\\n# \\u0631\\u0627 \\u0628\\u0627 \\u062a\\u0627\\u06a9\\u062a\\u06cc\\u06a9 \\u0647\\u0627\\u06cc \\u0645\\u062e\\u062a\\u0644\\u0641\\n# \\u062a\\u0633\\u062a \\u0645\\u06cc\\u06a9\\u0646\\u0647 \\u0648 \\u0647\\u0645\\u0647 \\u0627\\u06cc\\u0646\\u0647\\u0627 \\u0631\\u0648 \\u0628\\u0627\\u0647\\u0645 \\u0645\\u06cc\\u0627\\u0646\\u06af\\u06cc\\u0646 \\u0645\\u06cc\\u06af\\u06cc\\u0631\\u0647 \\u0648 \\u062d\\u0627\\u0635\\u0644 \\u06a9\\u0627\\u0631 \\u0631\\u0627 \\u0628\\u0647 \\u0645\\u0627 \\u0645\\u06cc\\u062f\\u0647\\n\\n# \\u06cc\\u0639\\u0646\\u06cc \\u0645\\u062b\\u0644 \\u0627\\u06cc\\u0646\\u0647 \\u06a9\\u0647 \\u0686\\u0646\\u062f\\u06cc\\u0646 \\u0627\\u0644\\u06af\\u0648\\u0631\\u06cc\\u062a\\u0645 \\u067e\\u06cc\\u0634 \\u0628\\u06cc\\u0646\\u06cc \\u0631\\u0648 \\u0628\\u0627 \\u0647\\u0645\\n# \\u0627\\u0633\\u062a\\u0641\\u0627\\u062f\\u0647 \\u06a9\\u0646\\u06cc \\u0648 \\u062f\\u0631 \\u0627\\u062e\\u0631 \\u062d\\u0627\\u0635\\u0644 \\u0645\\u06cc\\u0627\\u0646\\u06af\\u06cc\\u0646 \\u0647\\u0645\\u0634\\u0648\\u0646 \\u0631\\u0648 \\u0686\\u06cc\\u0632 \\u06a9\\u0646\\u06cc\\n\\nfrom sklearn.ensemble import RandomForestRegressor\\n\\n\\nforest_reg = RandomForestRegressor()\\n# \\u06cc\\u0627\\u062f\\u0628\\u06af\\u06cc\\u0631\\u06cc\\n\\nforest_reg.fit(housing_prepared_df, df_label)\\n\\n# \\u067e\\u06cc\\u0634 \\u0628\\u06cc\\u0646\\u06cc \\u06a9\\u0646\\nhousing_predictionss = forest_reg.predict(housing_prepared_df)\\n\\n\\nforest_scores = cross_val_score(\\n    forest_reg, housing_prepared_df, df_label, scoring=\\\"neg_mean_squared_error\\\", cv=10\\n)\\nforest_rmse_score = np.sqrt(-forest_scores)\\n\\n\\ndisplay_scores(forest_rmse_score, \\\"Random Forest Regressor\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# الگوریتم ۳\n",
    "# RandomForesRegressor\n",
    "# این الگوریتم \n",
    "# ensemble\n",
    "# است یعنی ترکیبی از الگوریتم های دیگر است\n",
    "# معمولا این الگوریتم ها زمان بر است اما دقیق تر است...\n",
    "\n",
    "# =======\n",
    "# خب \n",
    "# RandomForesRegressor\n",
    "# میاد از چندین \n",
    "# Decision Tree\n",
    "# استفاده میکنه\n",
    "# هر \n",
    "# Decision Tree \n",
    "# را با تاکتیک های مختلف \n",
    "# تست میکنه و همه اینها رو باهم میانگین میگیره و حاصل کار را به ما میده\n",
    "\n",
    "# یعنی مثل اینه که چندین الگوریتم پیش بینی رو با هم\n",
    "# استفاده کنی و در اخر حاصل میانگین همشون رو چیز کنی\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "# یادبگیری \n",
    "\n",
    "forest_reg.fit(housing_prepared_df, df_label)\n",
    "\n",
    "# پیش بینی کن\n",
    "housing_predictionss = forest_reg.predict(housing_prepared_df)\n",
    "\n",
    "\n",
    "\n",
    "forest_scores=cross_val_score(forest_reg,housing_prepared_df,df_label,scoring='neg_mean_squared_error',cv=10)\n",
    "forest_rmse_score=np.sqrt(-forest_scores)\n",
    "\n",
    "\n",
    "\n",
    "display_scores(forest_rmse_score,\"Random Forest Regressor\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099123de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c96a39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
